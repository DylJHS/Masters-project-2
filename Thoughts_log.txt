 
04/01/24

Thinking about editing the SoI-to-Control-set Wilcoxon Signed Rank test so as to become directional
I may not be able to use the wilcoxon paired test between the SoI and the control sets due the distribution of the difference between the two not being symmetrical around the median. This is because the skewness of both are the opposite of each other. 
Thinking about initialising a permutation test instead of the Wilcoxon test between the two sets for each control set
Can't use DESeq2 for the paired analysis unless i switch datasets, as it only takes raw RNA-seq counts as input

Creating a pre-analysis file for the exploratory analysis the set of interest
started to set up the Contrast analysis to test the SoI-to-Control_set pairings individually
 Should forget the contrast test given that it might just add complexity to the analysis as opposed to clarifying. Also the result that showed that each of the control sets does deviate significantly from the general trend. Not what I wanted but was confirmed by Adi that this is most likely to be expected given that I am dealing with cancer cells
Finished the Contrast Analysis, the result showed significant difference among the Set pairings (not what i wanted). But can move on. 


05/01/24

Starting to create the permutation paired test in the RNA_Analysis script
Reading up on the Fisher-Pitman permutation test
Considered adding a test for equality of variance following the permutation test, test aren't meant to handle paired data (ex: Levene's). So Choosing to display the variance among the pairings instead as is shown by the violin plots (similarity of widths) in Q1.A
 Making the test one-sided in order to reinforce the interpretation of the analysis
Finished the one-sided paired permutation test between the SoI and Control Set for each Set
Edited the RNA_Analysis to use the same control sets that are used in the charts to maintain a sense of consistency across the analysis


06/01/24

 going to start implementing the changes to the RNA_Analysis to the CNV Analysis
 Changes that will need to be made to the graphs in the script include:
- Converting the names of the samples/pairings on the x axes
- Finding the best colour palettes for the differences by tumour type
- Adding significant p-value indicators to the plots
- Making sure the plots are as understandable as possible

Editing the RNA_Analysis Q2.C to apply a one-sided paired permutation test between the SoI and the control sets when grouping by TSS
And therefore also removing the paired t.test that was in the Analysis previously


07/01/24

- Need to finish the RNA_Analysis up to the point that i can and then convert it for use with the CNV data as well

- Reading up on the multiple correction methods that might be best suited for the paired tests. 
- The type of test is caught between the BH method (large # of tests) & the BY method (as can't truly address the correlation between the tests, or if any are present)
- Likely to go with the BH method unless proven that there are dependencies between the tests
- Should consider switching from one-sided tests to two-sided as the assumption that the SoI showed as general higher expression than other genes was made after seeing the data. 
- Two-sided tests are a bit more conservative
- My initial hypothesis is that these genes show a differential expression pattern as opposed to solely a higher one
- So switching the tests to two-sided
- Changing the test in Q1.D so that it is not only two-sided but also corrected for using the BH method
- Edited the script in RNA_Analysis Part II in order to upload the entire dataset for the selected control set instead of using filtering the concatenated one
- The use of the full (only selected ~2000 rows of the 11000) allows for better analyses using more of the data
- Need to explore the data some more to check the number of samples for each cancer type and other such analyses that will help determine the types of tests that i can perform
- Should do the above using the Pre_Analysis script 
- All the paired tests grouping by cancer types come back as significant with a pvalue of 0 for all. This means that plotting them as i had in the previous version won't produce a highly discernible graph as all the points will appear on the same line
- I will use a barplot instead to show the average differential expression by cancer type (TSS) 
- Will also produce the same graph as before on 2 axes but using the diff expression vs the dif copy number once the copy number analysis is achieved
- Broke down the graph in Q2.A into facets based on the TSS group as opposed ot using colour palettes as there are not sufficient colours to cover each type
- Split the RNA_Analysis into 2 separate files for Part I and  Part II
- Created a barplot of the average differences in SoI vs Control Set for each TSS
 

08/01/24

- Editing the Notes file for the Project part I
- Added the interpretation to the mean TSS expression barplot (Q2.D)

- Edited the RNA_Analysis script to replace the 'Differential' terms with 'Difference'
- Considering changing the metric from Difference when assessing the differences in expression levels to Fold Change (ratio). This might be easier for interpretation given familiarity and removes the factor of the unit seeing as it is solely a relative (comparative) metric, which makes sense for the analyses at hand

- Reading the documentation on the CNV data generated using the GISTIC2.0 method
- Data is represented using log2 ratios
- Positive values indicate a gain in copy number. For instance, a log2 ratio of 1 would suggest a doubling (2^1 = 2) of the copy number in the test sample compared to the reference.
- Negative values indicate a loss in copy number. For example, a log2 ratio of -1 would suggest a halving (2^-1 = 0.5) of the copy number.


09/01/24

- Created the CNV pre-analysis Rmd script
- Analysis of the distribution of the CNV data

- Looking at the distribution of the CNV log2 ratios both the SoI and the Control Sets
- Looking at the distribution of the difference in the CNV values between the sets
- Leaving the RNA units untouched and using the difference in the comparison might be more valuable than assessing the ratio (FC) since I am assessing the sets of different genes and therefore the baseline expression in a ratio wouldn't make much sense
- Think about using tests of variance to show the spread of the data in each of the groupings that get applied
- Creating a Notes for the Part I of the analyses on the CNV data


10/01/24

- Configuring the CNV Analysis past Question 2
- Editing the graphs in both CNV and RNA analysis

- Finish updating the CNV analysis
- update the graphs in the RNA analysis (significance bars)

- Write down the remarks/questions for Stefan (PPI database pull down cutoff, Permutation tests, negative binomial in the RNA-seq data, differential analysis on different genes)


11/01/24

- Update the graphs in the RNA analysis
- try to implement some form of PCA 
- Or combine the graphs from the 2 analyses in some way
- Based on the meaning of the interaction score, it might be prudent to set a higher interaction cutoff
- meet with Theo. Advised to renormalise the data 
- should it be normalised per set (SoI & control) or across both (i.e. using the values across both sets as the normalisation parameter)
- Writing the rundown of the presentation
- In order to figure out how to re-normalise the data, figure out how it was normalised in the first place. 
- Was it across rows (samples) or columns (genes) or something different 


12/01/24

- Writing the Rundown for the presentation
- Writing the script for the presentation


13/01/24

- Writing the script for the presentation
- Constructing the Slides for the presentation
- Created a Notes file for the Main Literature References that will be used in my report(s)/presentations


14/01/24

- Using Whimsical for presentation pipeline diagram

- Whimsical is a scam


15/01/24

- Finished the presentation 
- Presented to the Lens & Janssen group


16/01/24

- My Anh's PhD Defence
- Reading up on the different methods for RNASeq normalisation (within&between samples & datasets)


17/01/24

- find out if re-normalisation is truly worth it

- Thinking of not normalising for the inter-set comparison
- But normalising for the intra-set analyses


18/01/24

- Starting the process of figuring out how to renormalise the set-of-interest subset

- Starting on the next Part of the Project (part II)
- Need to cut down the data to the set of interest only while renormalising the data

- In terms of the re-normalisation of the subset of genes it may no longer be a good idea. The process of normalising the data would average out some of the characteristics of the genes in the sample which may not be the best in terms of interpretation due to the fact that my hypothesis presumes that the genes in this set are distinct from the rest of the genome. Therefore even an average gene expression in this set could be indicative of something on a wider scale. Also the set is over-expressed when compared to the rest of the genome so lower expressed genes would not appear more like the rest of the genome but would show up as distinct on the lower side. 

- Talk with Stefan
- The iteration testing for the expression data was 'Overkill'
- Only showed what was expected in the most difficult way possible
- The genes of interest are likely just on the higher end of the overall expression histogram
- Using a normal control would prove more evident as that would show that there is a difference in the expected expression (normal vs cancerous)
- Moving forward suggested to:
- Correlate the genes within the subset to determine if there are genes that are covariates of one-another
- These correlated genes can then be grouped based on a z-score based signature 
- Signature can then be used for further analyses


- Talk did not go well, under the impression that my project is far too simple and convoluted than it should be
- Need to Organise the workflow better
- plan and determine which analyses to implement and why each one of them is beneficial and what they provide individual (i.e. what their purpose is)
- You are only using PanCan data so need to give extra thought to the meaning of the analyses that you are performing 
- Getting a healthy control set would be beneficial to the project as it would provide some basis for the normal functioning of the data that you are looking at

- Was also mentioned that STRING is likely not the best way to go about expanding the list of genes
- Would be more accurate to expand based on specific experimental data from select researchers

- Was slightly condescending
- Think more about finding other resources to assist you or give you suggestions

- Started writing the Gene_Subset_Analyis.Rmd which will contain the analyses for the correlations and the gene signature creation


19/01/24

- Continuing the Correlation analysis

- found a potential dataset for healthy data from different tissue types from https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE120795
- Saved as 'GSE120795_norm_counts_TPM_GRCh38.p13_NCBI.tsv' in the Raw_Data folder
- Copied and saved as 'Healthy_Data' in the RNA_Data folder 
- Data in only composed of RNAseq data 
- The values are normalised using TPM
- Also added the dataset for the values in their raw count form 
- Saved as 'GSE120795_raw_counts_GRCh38.p13_NCBI.tsv.gz' in the Raw_Data folder
- Copied and saved as 'Healthy_Data_raw_counts' in the RNA_Data folder 

- Reading up on GREAT at 'http://great.stanford.edu/public/html/splash.php' 
- This tool may not be relevant concerning the work that i am doing as it focuses on the cis regulatory regions of the input regions
- Returns the annotation terms that re significantly associated with the input regions/genes and their cis elements
- My focus is on the gene/regions themselves already knowing the function of most of the genes

- Recall that Stefan also mentioned a means of clustering such as k-means

- Correlated the RNA data using a Pearson correlation score (not measuring the distances but the similarity between the genes)
- Creating a heatmap for the correlation matrix
- Using Bioconductor's 'ComplexHeatmap' package
- 307*307 genes makes for a large matrix
- would like to turn it into a triangle plot seeing as the plot is symmetrical across the diagonal half the plot is redundant

- Would like to follow up the correlation matrix and test using a PCA to identify the clusters with more precision, create the signature genes and use those signatures as variables instead of the original list of genes which is quite long

- Created the same Correlation analysis file but for the CNV instead of the RNA data
- This seems like it might be the better approach as it comes from the CIN trait (CNV) back to the genetic trait as opposed to grouping by the RNA expression level and then trying to identify specific sets of genes for each 
- This way i am starting from the characteristic that I am interested in, CIN, and grouping at this level in order to identify traits that might be shared by different genes 
- Starting off with the CNV and then adding other CIN metrics to this in order to gain insight

- Need to find a way to break apart the different groupings in the clustermap 
- This will hopefully give me the individual genes that make up each of the groups


20/01/24

- Trying to find ways to extract the relevant clusters from the clusterplot

- Transforming the correlation map into a distance map

- Slightly confused about how the process will work so here is the rundown of how i see it:
- Create CNV signatures. These signatures are created based on the correlation between the CNVs that are observed in different genes within the data. The genes that are closely related based on the distance matrix (ex: 1 - Pearson's coef) are grouped together using a method such as k-means. 
- Each group makes up a CNV signature. 


21/01/24

- Might be useful to consider different clustering methods
- K-means clustering based on the Pearson correlation, but also others such as Mutual Information / Entropy
- Reading up on the methods for correlating RNA and feature extraction
- Thinking that using a Mutual information as the basis for the signatures could be beneficial due to the non-linearity of some of the relation


22/01/24

- Reading up more on the Mutual Information approach and the use of Spline functions to estimate RNA distributions
- Reading up on other features that could be added to the CIN set 
- Such as the HRD (Homologous Recombination Deficiency), hrd-loh, ai1 & lst1 Scores which are available on the XenaBrowser 

- Going to start with using Pearson's correlation as the basis of the RNA & CNV signatures
- Will then move on to using Mutual Information or another method
- And will increase the features for the CIN variables 

- Changing the distance measure for the CNV to euclidean is likely better
- This is because when dealing with Copy Number there is more than just directional changes that matter

- Created one distance matrix based on the Pearson and another based on the Euclidean distance
- finding a way to select the optimal number of groups using the k-means method
- Using the Silhouette method
- The Silhouette method does not show the best divisions between the groups when using k-means with the Pearson distance as well as the Euclidean distance
- The Silhouette score for both shows maximal at 2 clusters 
- Creating 2 broad CNV signatures does not seem effective for the purpose of extracting features from the variable
- Will likely have to implement a different clustering method (MI, Entropy ...) sooner than expected


23/01/24

- Emailing Reza about the updates to the Project and the Interim presentation


24/01/24

- Might be a good idea to remove genes that have NA values across any type of cancer for both the expression and the CNA data

- Might be thinking about this wrong
- Should i only be using the expression data of the genes of interest
- and then the CIN data (CNV and such) for the rest of the entire genome
- Instead of CIN data for only the genes of interest as well
- This is because i expect that a change in the regulation of the genes of interest is responsible for CIN in the LAD domains
- These LAD domains contain chromatin that is not related ot the sequences for the genes of interest
- I need to associate the expression patterns of the genes of interest to CIN signs (SV, Micronuclei, CNV) throughout the nucleus or specifically at LAD regions
- Can find specific sequences of cLADs to look at the issue at LAD specific regions
- Or gather as much CIN data about the samples as possible

- Can continue with the Pearson/euclidean/MI distance clustering 
- But base it only on the expression data not on the CNV data
- to get the expression patterns/signatures

- I want to relate the expression changes to changes in CIN data
- Need to perform clustering grouping such as i've been doing with the CNVs but using the entire genome data as opposed to solely the SoI
- Using this data that is genome wide and the patterns/signatures generated from this 
- Would like to relate it back to expression patterns in the Set of Interest (using either signatures/groupings or individual genes)

- Can do the above by creating two sets of signatures
- One that is/are expression signatures based solely on the expression patterns of the set of interest 
- Another that is/are CIN signatures that are based on the CIN data from the genome as a whole 
- Can also try to limit the CIN data to cLAD specific regions
 
- redownloaded the PanCan data as it somehow disappeared from the Raw_Data folder
- The data that was redownloaded includes RNA & CNV across multiple forms (SNP6, before and after germline removal, raw & norm counts...) 
- The data also includes the other data that refers to different datatypes (HDR signatures, survival info, phenotypes...) 

- Need to reformat the CNV data for the full genome data. Not sure if i should only use the after germline removal or the before as well. Will default to the post-removal


25/01/24

- Meeting with Aniek & Adi
- Need to integrate the Healthy RNAseq into the Analysis
- Forgot to mention about the Interim report that also needs to be written for the presentation

- Following up on the Healthy dataset by the Russian Academy of Sciences
- Looking through the list of cited by articles, looks to be cited by various papers
- Reliability of the data is a bit better given the citations
- Also found the citation to another dataset within the GTExPortal website
- This set may be better due to extensive number of samples and tissue sources 

- The GTEx Dataset (V8) has over 17000 samples 
- From 948 Donors
- Covering 54 Tissue types
- The healthy status of the donor is determined by the Death hardy Scale (DTHHRDY) which ranges from 0-4
- Only the 0th, 1st, 2nd, 3rd cases should satisfy your analysis
- The TPM RNA data that was downloaded was normalised for within sample variation (transcript length & seq depth)
- None of the data was normalised for a within Dataset normalisation
- Need to do that first applying either Quantile or TMM normalisation methods

- Back to reformatting the CNV data to incorporate the full genome data as opposed to only the set of interest

- Attended Marieke Oudelaar's seminar at Hubrecht 
- Went for the 3C and other chromatin conformation capturing techniques

- Met Lucia Barbadilla while I was there, she was speaking with Adi
- Would like to meet her again to get her input on some of the analyses

- Reza messaged me back
- Wants to have the presentation on the 16th of Feb 
- At VU
- Can do zoom for Aniek or Adi if cannot attend
- Need to send slides ahead of time
- NEED TO WRITE THE INTERIM REPORT
- presentation at around 2pm

 
26/01/24

- finish transforming the dataset with the CNVs for the full set
- The transformation is taking a long time due to the size of the dataset

- Handling the GTEx Healthy Set creation and preprocessing at the same time due to the time constraints imposed by the size of the datasets

- Created the csv file for the full CNV datatset
- Creating the csv file for the full GTEx dataset

- Downloaded and using the annotation file to identify samples (subjects) that need to be removed from the dataset
 
- Using Dask to clean/preprocess the GTEx dataset
- Using the values from the DTHHRDY variable in the meta data to remove the unhealthy samples from the full GTEx RNA dataset
- Values of 1-3 (exclude 0 and 4) are kept and considered healthy

- Using the Samples that come from the sources other than diseased (cancer...) cases
- Using the ventilator (0) cases as well as there is no indication that these subjects had a disease such as cancer prior to death
- In total this adds up to 842 distinct subjects
- End up with around 10,000 samples for healthy set


 27/01/24

- Continuing with the GTEx Healthy Samples Dataframe creation

- Saved the Healthy RNA GTEx samples in multiple files in the GTEx_RNA_Healthy folder in the RNA_Data folder
- Still need to normalise the samples for within dataset effects (TMM or quantile) 

- TMM is the likely option 
- This method would work due to the fact that the Samples are assumed to be from healthy individuals and not differentially expressed
- Created the usable CSV file for the count data as the DESeq2 only uses count data and not pre-normalised
- Once the data file for the count GTEx RNA data is created, will go through the preprocessing to remove the unwanted (unhealthy) samples
- Using GPT to translate the python processing script to R seeing as there is no DESeq2 python package

- Might be a good idea to translate the other scripts that were written in python over to R for improved consistency and overall readability


28/01/24

- Editing the GTEx csv file so that it does not contain an index when read into R script
- For comparing the healthy samples to the cancerous ones likely to need to apply a DGE analysis
- Will need to use the raw counts for this 
- Will also need to use DESeq2 library
- Should not normalise the counts for this
- Need to make sure that the genes are the same across datasets (i.e. remove the genes that are not common across datasets)
- Need to merge the datasets based on the common genes
- Need to ensure that the gene names are standardised across sets

- First want to put the healthy dataset through the same analysis that was done with TCGA dataset
- This will enable me to determine whether the genes of interest are differentially expressed in a healthy sample as well
- A DGE alone would only allow me to determine whether the genes are differentially expressed/regulated between cancer and healthy
- It would not allow me to determine if the difference between the control sets and SOI is also observed in healthy samples or not
- Need to do a TMM normalisation of the GTEx data for this part
- Actually keeping the values as TPM may be best for this part as the samples are not assumed to be differentially expressed and they are all from the same library therefore even though there are batch effects this is of no concern given that the interest is between genes
- Will be concerned with this later on though when comparing between samples and cancer types
- May have to remove the samples with RIN < 6 as they are considered unsuitable for RNA analyses
- Therefore downloaded the dataset which contains this meta data
- This will also be useful for the DGE and intra-set comparisons for batch effect normalisation
 
- Something to add to the tests that I have done in Part I of the project is that I was calculating the average expression values using the logs which means that I was calculating the geometric averages which are less prone to skewness by highly or lowly expressed genes
 
- I also need to figure out the GTEx sample labels based on the tissue type that they represent
- I need to reduce the genes in the GTEx dataset to the same ones that are in the TCGA dataset 


29/01/24
- Configuring the datasets for the TGEx Data
- Cleaning the Data
- removing the unusable samples
- Creating the GETx Set of Interest
- Creating the GTEx control sets that match up as well as possible with the TCGA control sets

 
- Need to run the script so that i have the files for use
- Will convert the script that is able to create the metrics datasets (comparing the SoI to the Controls based on the mean/median) to an R script so that the whole Part I Analysis can be run in the same script 
 

30/01/24

- Running the GTEx RNA DF configs again for the control sets that were not created

- Important to note that the RNA files that have been used so far from the GTEx are TPM normalised and therefore not suitable for inter-sample comparisons
- Finished creating the control sets for the GTEx RNA data
- The meta data variables that will likely be of use are:
- SAMPID: the ID for the sample
- The batch variables (SMNABTCH, SMNABTCHT, SMNABTCHD, SMGEBTCH, SMGEBTCHD, SMGEBTCHT, SMCEBNTER) that will used when correcting for batch effects
- SMTS/SMTSD: Th Tissue type that the sample comes from
 
Aniek Lecture:
- CIN is defined by the amount of instability in throughout the genome 
- This instability can be indicated by abnormal amount of variation in the genome as well
- Could be interesting to look at the variation patterns instead of static patterns for the signatures in the project
- Signatures could be based on Aneuploidy, Single Strand Breaks, DSBs, Micronuclei presence ... 
- Would be nice to be able to find a signature based on the SVs that occur in the samples maybe using the average or the count (need to find the seq data for each of the samples) (Luan's Phd book)
- Using log2(tpm+0.001) as the unit for the Part I of the GTEx analysis to avoid -inf values 
- This is also the unit that is used for the TCGA TPM RNA data
- Need to change the data that is used for the original RNA analysis to suit the analysis that is used now
- This means using the TPM data for the initial part
- Followed by the batch effect one later on

- Still configuring the Part I analysis for the GTEx RNA set


31/01/24

- Running the GTEx through the same tests as the TCGA set, shows that the difference between the set of interest and the controls may be present in healthy samples as well
- Will need to assess the degree of the difference after confirming that there is in fact a difference there
- Comparing the effect size of the differences between the conditions will likely also be of use


01/02/24

- Finishing running the script for the GTEx part I Analysis

- Running the Part I analysis on the GTEx data shows that there is a significant difference between the set of interest and the other control sets
- Need to evaluate if this difference between the differences is significant as well

- This can be done by comparing the differences between one of the statistically significant pairings of the GTEx data and one of the statistically significant pairings of the TCGA data

- Finished Q1 of part I of the GTEx RNA analysis
- In order to run Q2 (looking at the expression (SOI-control) set difference I must first normalise the data to factor in library size at the least and perhaps other batch effects as well
- Will have to repeat this process for the same part of the analysis with the TCGA data as well 
- Actually if the TCGA data is corrected for batch effects then this process does not require a renormalisation


02/02/24

- Reading about the different normalisation methods for the RNAseq data
- Reading the TMM paper and the reasons why this normalisation method is needed
- It improves on the usual scaling based solely on the number of reads (library size) but fail to account for gene composition 
- Meaning some genes may be more expressed than others in a specific lane (library) which will then skew the comparison with samples from other lanes (libraries)
- The above is caused by the limited sequencing ability that is provided by RNAseq 
- There is a certain amount of RNA reads available to be hybridised and elongated and therefore the most prevalent mRNA from the most highly expressed genes will be read
- And thereby obfuscating the rest of the transcriptome especially for comparative analyses

- This means when normalising the data, make sure to do it before subsetting the data
- Check whether or not the Tumour Purity is in the metadata for the TCGA data
 

03/02/24

- Reading up on the PRPS normalisation method that is meant to remove library size variation as well as plate effects from RNA data

- will need to apply a PCA to my raw data in order to identify potential causes of variation 
 

04/02/24

- Will likely not be able to apply successive normalisation factors (TPM, TMM, & Batch) to the same sample for cross genes and across sample comparisons

- May need to stop looking at the difference in expression once i switch over to the second question in the analysis
- I am making across sample comparisons and therefore cannot continue to use the TPM measure and should cease to make inter-gene comparisons
- I will just use the TMM method for the second question of the analyses as it kind of takes into account gene length, coverage detph and gene composition
- Might be useful to use PRPS later on though, so keep in mind

- Will be keeping the TPM counts for Q1&Q2 of the part I
- I am not making comparative calculations (fold changes ...) between the different sample types (tissues, health)  
- I am making the comparative calculations between the gene sets within the same samples grouped by type
 
- Therefore need to use TPM data for the first part (I) of the TCGA analysis as well as opposed to the data that has been transformed to account for batch effects

- Downloaded the TPM values from the Xena browser 

- Reconfigured the Github changing the remote repo name

- Transforming the TPM dataset into a csv dataset
- Need to reformat the IDs to the Gene names using the annotation file
- Couple issues with the current pipeline and changing from the Batch corrected TCGA data to the TPM
- The data uses the ENS codes instead of the genes
- but the STRING query requests the gene names not the ENS code
- Will have too adapt the code so that it can select either or both
- Right now will just manually configure the Dataframe configuration script to handle the TPM dataset

- The TPM file contains 40000 more identifying genes than the original batch normalised file
- This makes the processing quite slow


05/02/24

- Configuring the Dataframe Configuration script to be able to handle the TPM TCGA dataset
- Need to reconfigure the metadata files for the TCGA samples
- The codes for the samples incorporate more than just tissue but also other factors that could be important to filter on
- Such as Primary tumours vs other types
- Need to remove the Control Analyte sample from the TCGA TPM Dataset


06/02/24

- Need to reconfigure the initial python script that queries the STRING db and generates the control sets in order to handle TPM TCGA data instead of purely the Batch corrected data
- Added the extra genes to this script so that it contains the full list oof genes that show up in the selected list of proteins fo interest except for the ones that have no evidence of chromatin binding
- Need to find a way of speeding up the control set creation
- Could remove genes from the global pool of control genes after they have appeared a set number of times in control sets

- Make sure to keep the Github repo up to date

- For the GTEx control set generation need to set a threshold for the number of 'filler genes' that can be in a control set if all the genes in the corresponding TCGA set are not available

- For the GTEx data make sure to remove the samples that are marked to be excluded from the eQTL Analysis as they would allow for a more reliable analysis
- Figure out how many unique samples are analysed after removal of invalid samples 
- For duplicate samples (same indiv & tissue) select the sample with the highest RIN score


05/02/24

- Configuring the Dataframe Configuration script to be able to handle the TPM TCGA dataset
- Need to reconfigure the metadata files for the TCGA samples
- The codes for the samples incorporate more than just tissue but also other factors that could be important to filter on
- Such as Primary tumours vs other types
- Need to remove the Control Analyte sample from the TCGA TPM Dataset

- Need to reconfigure the initial python script that queries the STRING db and generates the control sets in order to handle TPM TCGA data instead of purely the Batch corrected data
- Added the extra genes to this script so that it contains the full list oof genes that show up in the selected list of proteins fo interest except for the ones that have no evidence of chromatin binding
- Need to find a way of speeding up the control set creation
- Could remove genes from the global pool of control genes after they have appeared a set number of times in control sets

- Make sure to keep the Github repo up to date

- For the GTEx control set generation need to set a threshold for the number of 'filler genes' that can be in a control set if all the genes in teh corresponding TCGA set are not available

- For the GTEx data make sure to remove the samples that are marked to be excluded from the eQTL Analysis as they would allow for a more reliable analysis
- Figure out how many unique samples are analysed after removal of invalid samples 
- For duplicate samples (same indiv & tissue) select the sample with the highest RIN score
 

07/02/24

- Translating the initial GTEx dataframe creation script to R from python

- Running the df creation in R is very slow
- if implemented it will need to be run on the HPC
- So doing the initial df building and cleaning in Python might be a benefit
- Trying again with the Fread() package though which should improve performance

 
- Both TCGA and the GTEx datasets use the ENSMEBL ID as a columns so can use this to relate the two datasets
- Best to keep the DF creation section in a python script for now

- Start from the beginning with the TCGA TPM set and then move on to the GTEx


08/02/24

- Configuring the combined df configuration script in python

- recreated most of the dataframes and sets to be used in the analyses
- Having trouble creating a shared control df for both the cancer and the non-cancerous sets
- Ideally these would contain the same genes across the GTEx and the TCGA sets so that the control sets that are created later on can be compared with more reliability

- Meeting with Adi and Aniek

- Emailed with Reza, need to send him the presentation slides on Monday
 

09/02/24

- Configuring the combined GTEx and TCGA df creation script
- Working on the Shared Control DF section
- look at the ID-Gene pairs to create the small datasets via iteration
- converting the numerical RNA expression values to float and rounding to the 10,000th (4th) decimal spot

- going to base the smaller control set creation mechanism off of the TCGA data as opposed to the GTEx data which is just there as an added control
- Using the TCGA Genes create a small control set of the same length as the gene column in TCGA SOI df with only the genes and the ids
- The genes are selected randomly from the TCGA Full Control dataset
- once the small tcga control df is created, create the corresponding one with the matching GTEx genes or ids
- for each row in the TCGA subset the GTEx subset row has to match with either the id, gene or both
- once the GTEx subset is completed, check this subset for any duplicates based on the gene-id pair
- if duplicates are found remove the x duplicate rows from the GTEx and the original row from the TCGA set
- find a replacement for the n number of genes that were removed from the TCGA set and start over with the process for a df of size n making sure not to select genes that already appeared in the subset
- continue with the process until the GTEx subset contains no duplicate genes


11/02/24

- Finished the Dataset configuration script in python 
- Created the control sets for both the GTEx and the TCGA sets 


12/02/24

- Editing the GTEx_Analysis script so that it can run with the newly created TPM SOI and control sets

- Edited the list of potential proteins of interest in the DF creation script to include the ones that are not identifiably LAD specific (BAF, TERB, MAJIN)
- Rerunning the DF creation script with the updated list for the STRING query
- Got a total of 547 control sets for this run as opposed to the ~587 I got on the previous run
- Still editing the script so that it is compliant with the different number of control sets


13/02/24

- Finished the GTEx RNA Analysis R script for the first part of the analysis
- Finished creating and saving the plot for the GTEx RNA Analysis in R 

- In terms of the next part of the RNA analysis: 
- 1: DGEA for the genes in the SOI for the cancer to non-cancerous condition for each cancer type
- 2: Any gene that does not reach a certain threshold, set in terms of the p-val and effect size/log fold change in at least one of the pairwise comparisons is dropped from the set
- Important to note that the DGEA is performed between tissue specific cohorts of the GTEx and TCGA RNA data
- 3: Use of correlation distance matrix (Pearson or Spearman) 
- 4: cluster the genes together creating specific groupings or signatures
- 4: for each sample calculate the mean of each signature
- 5: standardise the signatures by applying a z-scaling method
- 6: Assign the signature  Z-scores to each of the samples 

- In terms of the CIN based analysis: 
- 1: for the CNV data, remove genes (or chromosome regions if based on seq) that show no variation across all samples 
- 2: Repeat for the signature data (HDR, ai1, hrd-loh, lst1) 
- 3: For each of 
 

15/02/24

- Cons of current signature methodologies is the need for intense computational needs with regards to whole genome wide sequencing in order to pick up on SNPs, SSBs, DSBs, Indels and other genomic artifacts that occur at the nucleotide level
- Cons of my methodology is that it relies on such signatures having already been created for the analysis 
- Not an issue if the needed signatures can be generated rapidly without the need for intense computations


- Might be helpful to look at ovarian cancer in particular
- Writing the interim report based on the Notes taken during the steps of the analysis on the TPM RNA datasets
- Leaving out the CNV analysis as it is part of the 2nd part of the analysis

- Fixed the TCGA TPM Analysis all the way to the end of the script so that it can use the data all the way through
 

16/02/24

- Finished the first part of the Report
- Edited for the interim presentation 'Interim Presentation'
- Gave the presentation to Reza
- Went well
- Points given: 
   - use the healthy data from the in order to get better reliability from the data
   - using the TCGA healthy data also gives better indication of the effect between the SOI and the non-cancerous controls
   - Edit the presentation and the reports to use the term 'LAD/Heterochromatin coding' for proteins and genes instead of just 'LAD/Heterochromatin' which gives the impression that I am referring to the actual genes at those positions as it's confusing
   - Think about using a density-based clustering method as it may be better for interaction based similarities than distance
   - Also could be interesting to add GSEA to get an idea of the functional landscape of the proteins being identified


 

16/02/24

- Finished the first part of the Report
- Edited for the interim presentation 'Interim Presentation'
- Gave the presentation to Reza
- Went well
- Points given: 
   - use the healthy data from the in order to get better reliability from the data
   - using the TCGA healthy data also gives better indication of the effect between the SOI and the non-cancerous controls
   - Edit the presentation and the reports to use the term 'LAD/Heterochromatin coding' for proteins and genes instead of just 'LAD/Heterochromatin' which gives the impression that I am refering to the actual genes at those positions (low transcription)
   - Think about using a density-based clustering method as it may be better for interaction based similarities than distance



19/02/24

- Going over the TCGA healthy data to see if i can integrate it into the analysis 
- Will only integrate it if it shows better reliability than the GTEx data
- If the healthy data comes from the same samples than this is a greater advantage over the GTEx as it removes inter-sample (indiv) variation
- But will likely have to remove the metastatic cases if I go with the TCGA non-cancerous data as they may be compromised in terms of their transcriptome
- or just analyse the metastatic cases separately 
- Also check on the tissues types for the non-cancerous data as if they do not supply sufficient tissue type samples the dat may not be able to be analysed in the best manner

- Adi wants to check the STRING output for reliability of the genes being given
- when applying an interaction score of 900 (higher was too high)
- Got 74 genes
- Comprised of the following: 
'H3C13', 'H1-4', 'H3C12', 'H3C14', 'PCGF2', 'LEMD3', 'SUV39H1', 'E2F6', 'IFFO1', 'MECP2', 'H3C11', 'LMNB2', 'H3C7', 'L3MBTL1', 'TERB2', 'CBX3', 'H3C1', 'TOR1AIP1', 'CBX5', 'LEMD2', 'EMD', 'H3C4', 'SUN1', 'PAX6', 'RING1', 'H3C8', 'BCLAF1', 'MAPRE1', 'SMARCA4', 'SLC25A3', 'SUN2', 'TRIM28', 'PCGF6', 'CACNB4', 'H3C2', 'BANF2', 'BMI1', 'SYNE1', 'TERF1', 'TMPO', 'SETDB1', 'H3-3A', 'H3C6', 'BANF1', 'BAF', 'H3-3B', 'H3C10', 'CHMP7', 'LMO7', 'H3-4', 'SGO1', 'CBX1', 'CTNNB1', 'PRR14', 'LBR', 'H3C15', 'COMMD3-BMI1', 'MAJIN', 'TM7SF2', 'LMNB1', 'TERB1', 'SYNE2', 'XRCC4', 'L3MBTL2', 'KPNB1', 'KDM1A', 'MAN1', 'H3C3', 'H3-2', 'SMAD2', 'LMNA', 'EHMT2', 'H3-5', 'SMAD1'
- Should check these at a later time
 
- got the full list of non-cancer data from the TCGA file
- The file (TPM) contains 677 participants with both a 'Primary Solid Tumour' and a 'Solid Tissue Normal'
- The files do not contain info about the origin of the Normal tissue but the samples still have the TSS code
- So can presume that the Tissue type is related to the Study.Name 
- 
- The Study.Name will give the name of the cancer type of interest in the sample
 

20/02/24

- Adapting the initial analysis script to handle the controls from the TCGA instead of the controls from GTEx
- first need to reconfigure the control set initialisation step in python

- Concerning the Solid Tissue Normal definition, it usually corresponds to matching non-malignant type of the same tissue that is being analysed in the study

- Creating a dataset with all the genes and all the samples

- Will need to edit the TCGA_GTEx_DF_CONFIG.py to include a step that creates a full df with all the genes and all the samples and saves the dataset
 

21/02/24

- Configured a script that is able to create the normal control sets for the analysis of the TCGA samples
- Will have to integrate it into the Full DF configuration script once it is fully running 

- Put the Normal TCGA samples through the same analysis as the cancer samples
- Did not show a significant change from the result that was performed with the cancer samples
- Will be able to change the analysis somewhat now though as i have both cancer data and non-cancer data from the same individual 
- I can perform paired comparisons between the conditions on the full SOI before doing it for the individual genes with DGEA
 
- Edited the notes for the project part I to take into account the paired normal samples 

22/02/24

- Going over the initial output from string using the 900 interaction score cutoff
 
- Might be interesting to run through the analysis solely using the genes with an interaction score cutoff of 0.900
- Also thinking about booking a final date in August

- Going to use 950 as the cutoff for the confidence score on the verification analysis instead of 900 as the former will return ~53 genes
 
- Started the script to analyse the SOI difference between the cancerous data and the non-cancerous data
- Wilcoxon-Signed-Rank test shows that there is a significant difference between the mean of the 2 groups
 

23/02/24

- Following up on the Wilcoxon-signed-Rank test (2 sample paired wilcoxon test) between the SOI across the 2 conditions w/ the same test but across the multiple controls
- Will need to correct for FDR 

 
- Reminder that the reason for the implementation of the paired permutation test was due the the assumption of symmetry by the wilcoxon signed rank test
- This assumption however, only needs to be met under the null hypo
- In my case meaning: 
   - We assume that the difference between the same gene-sets (e.g SOI) in different conditions (tumour vs normal) would follow a symmetrical distribution 
- In this case the distribution does fit the assumption
- Shown by both the boxplot and the skewness value between 0 and 0.5 on an infinite scale
 

24/02/24

- Continuing with the analysis of the TCGA normal vs cancerous aggregate data
- implemented facetted paired plot to visualise and compare the difference in the mean expression of the SOI as well as 5 other control sets across the conditions
- This still needs some edits
- including changing the numbering at the end of the column names, ex: from 'geom_mean_nrm1' to geom_mean-nrm_1' 
- This way when creating the set groups for faceting in the plot different sets don't get grouped together (ex: 55 and 5)
- Also need to finish the assessment of the SOI significance vs those of all other controls
- Want to do this by comparing the significance value from the paired wilcoxon test from the SOI to all others
- Assess the % of the others that are also:
   1) significant
   2) of a similar level (based on the **** signs)
   3) of equal or better significance 
- Want to build up distribution of the significances for paired wilcoxon tests 
- highlight ours, and maybe highlight a subset of the rest using the descriptors above (1-3)



27/02/24

- Continuing with the analysis of the non-cancerous vs the cancerous data 
- Plotting the volcano plot of the log2FC across the various sets including the SOI
- the log2FC is calculated using the mean values (mean of the individual log2 values of each gene in the set, taking that of the cancerous set - non-cancerous set) 


28/02/24
- Continuing with the analysis of the non-cancerous vs the cancerous conditions in the sets
- the Volcano plot is done 
- The Comparative table for the summary of the number of significant sets is done
- Editing the script with annotations for comprehension 
- Maybe add a cloud around the points in the volcano plot to show the variance or std for each set

29/02/24

- Need to rerun the script and edit it to take into account the std for each of the sets
- Add a cloud around each point in the volcano plot 
- The cloud will represent the average (mean) std of the difference between conditions for paired samples for each set
 
- Also need to start with the actual DGEA
- Think about removing the Cancerous types with few samples 
- I think those with less than around 30 samples might be a good number 
- Or can do a power analysis of the number to get an idea of the correct number

- Finished the volcano plot with the added grey background points for the std of the differences
- Converted the log FC from using the difference of the mean Log2 of each condition to using the mean of the differences of the individual log2 values across each pair

 
- combining all the part I analyses into a single Rmd file


01/03/24

- Combined the 3 separate analysis scripts into a single Rmd file
- the 3 were the: 
   - TCGA cancer analysis, TCGA_TPM_Analysis_I
   - TCGA normal analysis, TCGA_TPM_mRNA_NORMAL_ANALYSIS
   - TCGA Cancer/Normal analysis, TCGA_TUMOUR-NORMAL_ANALYSIS

- Need to incorporate a tissue-specific analysis of the in the Cancer/Normal analysis

- Convert all two-sided tests to one-sided based on the SOI and the cancer type
- Cancer should be 'greater' when assessed against normal type
- SOI should also be 'greater' when assessed against the other sets of the same type


- Finished annotating the script for the first part of the analysis (intra-conditional)

 

04/03/23

- Need to finish annotating the full script for the combined analysis

- also need to include a way to visualise and measure the general upregulation in the conditions base don the tissue type
- To do this i will need to merge the all combos df with the meta data in order to get the tissue types for each participant
- Parse the data by each type and applying a significance test between the geom means of both groups (paired test)
- Get the significance and the mean log2FC of the differences between the conditions for each of the tissue types



05/03/24

- Continuing with the tissue-speicfic analysis of the interconditional part of the full script

- Plotting the volcano plots in terms of the specific tissue types 
- The calculations of the p-values for these plots are only done correcting for the control sets used for each cancer type 
- So using a BH correction assuming the number of repeated test is equal to the number of control datasets and not the number of control datasets for each cancer type
- The plot have not been tuing out as expected
- Very few of the SOIs come up as significant or display as much difference compared to the controls as was expected based on the same plot without splitting up the data into distinct cancer groups
- In the later plot the SOI is isolated but highly significant and with a different log2FC when compared to all controls

- Editing the script so that every significance test is done using a two-sided test instead of one-sided
- This lines up with the methodology as I am hypothesising that the SOI shows a DIFFERENT expression pattern in cancer vs normal instead of increased or decreased expression

- Don't use adjusted p values in volcano plots


06/03/24

- Creating the individual volcano plots based on the tissue types
- Creating the corresponding dfs as well
 
- Finished creating the volcano plots for the tissue types 
- Both the separate plots for the individual tissue types
- And for the combined plot which combines all of the plots from the above into a single one
- Changed the tissue type name from the full tumour type to the Tumour type abbreviation to save on space in the figs

-  Meeting with Adi and Stefan tomorrow need to come up with questions for him
- Will focus on the computational signature building aspect of the project as opposed to the coding


- Need to write up the results and interpretation for the inter-conditional part of the analysis
- Section F and below
- 
 

07/03/24

- Prepping for the meeting with Stefan
- Reading up on the CIN based datatypes 
- Including: loh, telomeric allelic imbalance, large scale state transition and HRD scores

- Arianna presentation notes:
- Might be nice to look for SMC5/6, Gcn5 and Qjt in the list of proteins/genes of interest from the STRING output

- Marit presentation notes:
- Might be interesting to check for the following proteins in the STRING output:
- JMJD1C, SETDB1, SIRT2, KAT5, SUV39H1/2

Meeting with Stefan: 
- should not use the DGE to remove genes that are not up-regulated
- should think about removing genes that are down-regulated
- Build the signatures using a classifier with the RNAseq data as the input variables and the CIN features as the classes
- Fine tune the model using GLM to reduce the number of genes in each of the signatures to the least number while maintaining a fairly sufficient accuracy
- Perhaps look at the mutations within the samples to try to parse out the effect of these mutations 
- Focusing on the main cancer driving mutations
 
- Reading Stefan's Breast Cancer Paper
- Only used genes up-regulated by GCs (not sure why not also down-regulated)
- And restricted the gene union to genes that were significantly up-regulated in at least 3 models (could be interesting to apply this but using the tumour types instead)
- The use of only up-regulated genes was due to them wanting the study the effect that was brought on when GR were stimulated by GCs thereby activating 
- As is described in the 'Liberzon et al, 2015' paper
- The Liberzon paper also goes into detail on the lowest and highest number of genes it used for the signature
- Needing to be between 15 and 200 in order to function correctly 
- my personal analysis is not looking for the same kind of effect, and can incorporate more than one signature therefore do not need to limit it to genes which are up-regulated



08/03/24

- Thinking that a DGEA is still useful to see the response of the genes of interest to cancer
- Will use a ssGSEA on the individual signatures once they are created 

- For the DGEA might be more useful to use the Signed Rank test (wilcoxon) due to the large number of samples and hence increased power and decreased FDR
- Can either use the TPMs or renormalise the raw counts with TMM or something
- Still need to read up on the paired DGEA though to confirm


11/03/24

- Use limma voom for the DGEA making sure to use the patient as a factor as well
- Before running, check the data using pca
- Also would be nice to use Wilocxon Signed Rank test as a comparitive benchmark for the DGE genes given that I am using a large sample set

 

12/03/24

- Commencing the DGE
- using the Expected Counts from the Xena Browser
- have to un-transform the data from log2(x+1)

- Using the TMM as the accross sample normalisation factor quantification calculation but would like to use at least another one as well to test against (RLE, HTN...)

- Editing the df so that it only contains normal and primary type cancer samples (no metastatic, cell lines ...

- also need to edit the sample names so that it doens't contain the tissue_type code (01,02,05...)
- But instead the participant number followed by the tissue category (normal or cancerous: 0 or 1)
 

13/03/24

- Continuing with the DGEA of the individual genes in from the TCGA
- Removing the samples with library sizes of 0 
 

14/03/24

- Continuing with the DGE analysis of the TCGA data
- Need to model based on the participant and the tissue status

- I've been trying to use the DGE with the entire genome but maybe should only apply it with the SOI
- This will speed up the analysis but will limit the interpretability by limiting the number of genes in the analysis

- Finished the main part of the DGEA for the SOI 
- Still need to include a volcano plot to show the main genes that are DE
- Also need to repeat the test using the cancer type as an interaction effect
- And will need to repeat the test using the full set of genes instead of just the set of interest

- Changed the name of the tissue_type to tissue_status for the cancer vs normal category
- The tissue_type is now the TSS or Tissue Source Site (sample's tissue of origin)
 

15/03/24

- Continuing with the DGE but adding the tumour type as an additional main effect

- Having issues using the tumour_type as an additional main effect
- The model is not able to estimate the coefficients for each of the factors (types) 
- Could group certain tumours together
- Think i will just perform the DGEA for the individual tumour types instead of using the tumour_type as a main effect


18/03/24

- continuing with the DGE but implementing it with full gene list which is quite slow
- Running on close to 60000 genes as opposed to the ~300 from the SOI
 
- Figured out how to connect to the hpc network
- Reading up on the documentation for the hpc 
- Trying to figure out how to use R & Rstudio with the hpc
- Will ask Theo or Tessa on how they do this


19/03/24

- Ran the DGEA for all genes overnight 
- Highlighting the GOIs in the volcano plot 
- Annotating the script for the analysis above

- When applying DGE important to order the factors (here conditions) accordingly 
- Need to reorder mine with 'Normal' being specified first seeing as it is the reference and then 'Cancer'
- levels  = c('Normal', 'Cancer')
- the order will determine how the log2fc is calculated and therefore if the order is wrong over-expressed/under-expressed genes will be reversed based on the condition

- Cancer/Tissue types to keep are the Breast, Head and neck, Liver hepatocellular and the lung squamous 


20/03/24

- Ran the full gene DGE after correcting the up/down-regulation on the axis
- Issues when running and trying to correct the axis 
- Need to do again

- Ran DGE for each type of tissue/cancer that has more than one paired sample 
- The MDS for most types showed a high degree of separation based on the first FC component of around 20%-50%
- Meaning that for a specific tissue type using the RNAseq data only, a linear model has a good chance of being able to accurately classify cancer vs normal 


21/03/24

- Try to repeat the use of the cancer/tissue type as a main effect but use the abbrvs instead of the TSS codes which may be introducing noise seeing as there are so many of them. 
- Looking through the list of genes with the highest expression is showing a variety of genes (CENPA, DNMT3B, and other kinesin/microtubule coding genes)

- Would be interesting to perform the complete analysis once it's done using a multitude of parameters 
- For the STRING interaction score would be nice to use: 0.95, 0.80 and 0.65 for a wider range of potential targets
- would come once the entire pipeline has been implemented though

- Tried to include the tissue type in the model for the DGE
- Did not amount to much 
- With the following Warning: Partial NA coefficients for 327 probe(s)

- Need to start implementing the expression based signatures using the complete RNAseq data from the TCGA set
 

22/03/24

- Annotating the DGE script and adding the Results and Interpretation to the script
 
- Reading up on the clustering method SOM (Self Organising Matrix) 

- For the creation of the expression-based signatures
- Either use the TPM data or Normalise the  count data with normalisation factors based on library size
- Create the correlation matrix between the values
- Genes that show a very high correlation (in the same direction and of maybe 0.9 or higher) should be grouped into the same variable 
- This variable should use the combined names of all the genes that make up this poly-gene separated by a specific cahracter
- The values that are shown for this poly-gene shoud be based on the mean of the values for each component gene 
- This should remove some of the genes from the dataset thereby reducing its dimensionality
- The new matrix that now contains the genes and the polygenes can be used for the hierarchal clsutering using an approriate method
 

25/03/24

- Reading up on the GLMs 
- Slightly confused about how the individual signatures should be built
- Should i build the signatures before hand and then try to relate them to the CIN features using a classifier 
- Or should i keep the expression values in the gene/semi-gene form and relate these to the CIN features using the classifier 
- Will need to read up on the different ways that Signatures have been created and if GLMs have been used and how GLMs have been used in a similar context
 
- Might be a good idea to go with both approaches 
- Starting with a metagene approach
- Clustering genes based on the expression data
- and then using these clusters for the classification 

- And to go with gene level approach as well
- Avoiding the clustering 
- And building the classifier directly on these values

- For the DGEA I need to redo it with the full dataset as performing the normalisation factor calculation on a subset of the data can induce bias into the factors when determining the reference sample and the scaling factors


26/03/24

- Updating the DGE Analysis Graphs and the automation of their saving to the plots folder
 
- Thinking about the creation of the expressional signatures using the first approach
- the first approach is first clustering genes by correlation of their expressional profiles
- Doesn't make sense to cluster based on the absolute value of the correlation 
- Should only cluster based on the directionality and the magnitude of the correlation
- Use elbow plot or silhouette plot to determine the adequate number of clusters
- This clustering method is only used as a means of reducing the covariance that is likely to be seen between many of the genes
- So the resulting correlation matrix made up using the z scores of the metagenes should optimally show as little covariance as possible 
- Should use this as the optimisation metric:

Optimisation measure: 
- Using the correlation matrix of the complete gene expression dataset 
- Create the distance matrix (Pearson based)
- Create n= 2 gene-based clusters (based on directionality and magnitude of the correlation values) using hierarchical clustering (specifying n = 2)
- Group the original RNAseq data on the defined clusters aggregating the RNAseq counts using the mean for each observation (sample)
- for each cluster calculate the z-score associated with every sample based the mean count that was calculated in the previous step
- Replace mean value with the z-score for each cluster and observation
- Calculate the squared correlation coefficient between the two clusters based on the 2 z-scores present for each observation
- Save the correlation coefficient

- Reinitialise the initial correlation matrix based on the original count data
- Create n= 3 gene-based clusters (based on directionality and magnitude of the correlation values) using hierarchical clustering (specifying n = 3)
- Group the original RNAseq data on the defined clusters aggregating the RNAseq counts using the mean for each observation (sample)
- for each cluster calculate the z-score associated with every sample based the mean count that was calculated in the previous step
- Replace mean value with the z-score for each cluster and observation
- Calculate the cluster-based correlation matrix for the 3 clusters based on the 3 z-scores present for each observation
- Calculate the combined cluster covariance score: sum of each squared pairwise correlation coefficients (cluster1-cluster2 correlation coef squared + cluster1-cluster3 correlation coef squared + cluster3-cluster2 correlation coef squared) divided by the number of possible cluster pairs i.e the possible combinations made up of 2 clusters (in this case 3)
- Save the combined cluster covariance score associated with 3 clusters

- Reinitialise the initial correlation matrix based on the original count data and repeat the above increasing n by one until n = the number of individual genes in the original dataset
- Refer back to the cluster covariance scores and implement the number of clusters associated with the lowest cluster covariance score 
- If more than one method resulted in the same score, implement the one with the fewest clusters

- The method described above might result in a similar to the result that would be obtained using a PCA 
- But they are likely to be different to some degree and offer different insights
- Will perform both PCA based dim reduction and the method described above


27/03/24

- Writing the script for the cluster/dim reduction using the correlation method
 
- Might need to do some more data exploration before initialising the signature script
- Would to know if the metastatic samples impact the RNAseq values in a significant way a
- Would help me to know if i should include them or not in the analysis 
- Also need to get a sense of the number of samples in each group which includes both the tissue type (cancer type) and the sample type (metastatic, primary ...) 
- Visualising with MDS based on both of these would also help identify potential patterns


28/03/24

- Creating the exploration script for the raw counts 
- Initialised the script for the Signature creation using the hierarchal clustering method

- No need to use the PCA method or can do it but should not be prioritised as the interpretation of the loadings may be meaningless
- Need to re-run the DGEA for the full genes due to an issue that came up with the un-transformation of the data


29/03/24

- Used the wrong count data for the DGEA used normalised count data
- Need to repeat the Analysis using the Expected Counts from Xena
 
- For the clustering analysis will need to normalise the counts for library size and then log2 transform them before applying the clustering scaling 
 
- The Script needs to be updated somewhat due to:
	- The Genes being in the form of ENSMBL ids and not the gene names (may require the use of the same id to name translation across the STRING as well as DGEA scripts for consistency and reliability)
	- The dataset showing duplicate genes which need to be coerced using the median
(The above is taking a lot longer than expected, might need to use the HPC to deal with it later on)


02/04/24

- Continuing with the data exploration that will help with the clustering

- Created the table of contents and the section titles for the DGEA script
- Still need to include the interpretation sections

- Edited the untransform() function in the DGEA and explore script 
- The function had the right formula but was returning a decimal whereas counts should be integers

- Trying to apply MDS (PCoA) to the full cancer data (after removal of the normal data) this is to get a sense of the effect of the different variables such as the sample type and the tissue type and the combine tissue-sample type
- Also helps determine the number of samples needed for the correct clustering


03/04/24

- Configuring the Exploration script to run the MDS on the full cancer data 
- Want to be able to analyse the datapoints in terms of the Sample Type - Tissue Type interaction 
 
- Configured the exploration script to use the scaling factors obtained from the calcnormalisation() function
- Used sweep() to divide every row (gene) for each column (sample) in the matrix by the same normalisation factor
- Yielding the library-scaled gene counts

- need to apply the dist() function in such a way for the distances to be calculated between the samples and not the genes 
- Need to transpose the df first before applying the dist() function 
- After that i can use MDS on the data and plot in function of the Sample-Tissue type interaction


04/04/24

- Lab meeting: Marieke and Lucie presentation update
- Over-expression of HP1 in flies seems to imbue them with a certain amount of starvation stress resistance but that only appears for pre-treated flies (fed with RU up to a certain point and then RU is removed from the food source

- One-on-One meeting with Aniek and Adi: 
- Set up a meeting with Marit based on her project on het proteins and how they might be regulated or altered in cancer or specific cancer types
- Cross reference with the genes that are DE in my set and what she has
 
- Setting up R on the HPC
- Created my folder in the hpc/shared/prekovic folder
- Downloaded the R version to use
- Uploaded my data to the data/Janssen/chromatin_cancer/dhaynessimmons folder in the current_data subfolder
- Data transfer was interrupted, need to check which data was added 

- Need to rewrite the Exploration script into an R script to be able to run with the hpc
 

05/04/24

- Checking the data that was uploaded to the umc folder 
 
- the data for the exploration analysis has been loaded onto both my folder within the umc's data/Janssen/chromatin_cancer folder and the hpc/shared/prekovic folder

-in order to run the r scripts on the hpc, need to:
    - Write the script in R making sure to specify the input and the output (graphs, csv files ...)
    - load the data and the script into my folder in the hpc/shared/prekovic folder 
    - Create the R environment in my hpc folder
    - Install the packages that I need for the scripts
    - Activate the environment 
    - write the shell script with the sbatch options embedded at the top of the script
    - run the sbatch using Slurm commands


06/04/24

- Initialising the r_environment in the hpc/shared/prekovic/dhaynessimmons
- Installing the commonly used packages in the same folder for use 

- Configured VSCode to run on the hpc 
- Configured the .sh script for the counts_xplr analysis
- the script is not able to run for something to do with the script itself
- Will remove the marks at the start and end of the script indicating where the R scrip begins and ends to see if that works
- The simple script was able to run so think the solution above should work

In order to run the scripts for r: 
- Need to write the R script
- Need to write the Shell (.sh) script with the #SBATCH options that suit the script 
- Need to activate the r_env (not sure if i need to leave this in the .sh script as well or if running it alone before the Shell would work)
- Submit the batch with sbatch specifying the Shell script 


07/04/24

- Running the script in the hpc seems to be working 
- Have not figured out the correct duration/memory usage to get it through the entire script yet
- Using 2:20:00 as the duration and 60GB MEM to see if this works
 
- Rant he most of the script, just waiting on the dist() matrix
- 
- As well as the MDS 
- Not sure what form this will take
- Might need to use a smaller df as a test if the script is not run tonight
 
- I think i forgot to reduce the expression set to only include the genes of interest even in the exploratory analysis
- Will need to include this in the analysis which will help reduce the dimensionality of the data by a lot and will increase the performance of the analyses
- Might not need the hpc in order to build the distance matrix given that the set will be reduced to around 300 genes from the previous 60000


08/04/24

- Downloaded the complete transposed df from the hpc
- For the Counts_xplr script editing so that the reduction in the genes to the genes of interest only happens once the normalisation factors have been calculated as need to base these off of as many genes as possible

- MDS worked on the test set after the filtering down to the GOIs
- Editing the script for R and hpc integration

- Remember that the MDS is being run using a distance matrix because running it using only the expression matrix with edgeR assumes that it is being run for a DGE which in this case it is not
 

09/04/24

- Got the mds plots back
- Coloured by sample type as well as tissue/cancer type
- They are not very indicative as the majority of the points seem to be concentrated around the 0 on the V1 
- Think this is due to the fact that i need to normalise the data in addition to the library size factorisation that was already performed

- Look into Nextflow and read into it
- Likely to be very useful in terms of the implementation of the analysis from start to finish

- made a mistake when i said that i needed to normalise the data in addition to the library size scaling
- Just need to log transform the scaled data 
- Will log transform the gene counts after they are scaled
 
- The issue with the hierarchical clustering method that i came up with is that the optimal number of genes in each cluster may not always be the same
- I think the main hierarchical clustering algorithm may be able to solve this using the distance between clusters as the breaking point for determining the number of clusters instead of the number of features (genes) in each cluster
- Likely to use Ward's method of calculating the distance between clusters

- Clustering the genes into groups before the classification is a moo point if there are very few highly correlated genes in the first place
- Want to assess the correlation between the genes and then see

- Got the full exploration script returned by the hpc
- There do not seem to be outliers in the data in terms of the tissue/cancer type or the sample type
- There are two outliers in the MDS plots 'sample_mds_plot.png' and 'cancer_mds_plot.png' but they are not unique in terms of their sample or tissue (cancer) types

- For the clustering based on genes need to use the TPM data as making comparisons/groupings between genes and scaling based on library size would have a very small impact on this comparison

- Forgot to analyse the count data in terms of the interaction effect (sample type - tissue type interaction) in the mds plot
 

10/04/24

- For the clustering will first render the correlation matrix
- Don't think i need to untransform the data beforehand
- 
 

11/04/24

- Building the correlation matrix for the Genes of interest

- Keeping the log transformation seems like a better choice as it allows for better linearity in the Pearson correlation which is essential

- Continuing the clustering script
- Format the df for use as a correlation & distance matrix
- Created the correlation matrix
- A few clusters that have a potential to be formed
- But conflicting clusters for the groups of genes
- Need to use the algorithm to determine which clusters should be formed over others

- The algorithm that i came up with will not work using the summation of the correlation coefficients
- Equally negative and positive values will cancel each other out but having negative values is better than an equally positive value
- The above requirement also excludes the use of solely the square and the absolute

- Created the distance matrix
- clusters are still apparent
- clustering of the distance matrix using hierarchical clustering 
- The average method of calculating the distance between clusters is used in the hclust() function

- Extracted the dendrogram
- Played around with the denextend function
- Cutting the tree at different points, seeing the clusters formed ...

 

12/04/24

- Reconfigured the optimisation algorithm for the selection of the number of clusters
- Summation of the square of the gene correlation coefficients multiplied by 1 for negative values and 2 for positive values 
- Algorithm will search for the lowest possible value from the above

- Configuring the script that loops over the different node heights from the clustered dendrogram
- For each height: 
   - Creates the new clusters
   - Gets the genes that are in each cluster
   - merges the original gene expression data with the gene cluster info
   - Groups the resulting df by cluster, averaging the log expression values
   - Recalculates the correlation coefficients using the clusters and individual genes
   - Calculates and saves the resulting coefficient score  

 
- Might need to make a addition to the clustering optimisation algorithm
- Currently trying to maximise the non-correlation between genes/clusters 
- Might need to find a way of maintaining or maximising the correlation within clusters as well
- Effectively turning the algorithm into a Correlation Clustering algorithm

- Also need to consider the fact that the more clusters i have, the lower the summation is likely to be
- Should consider adding in a term to take this into account
- Using the average of the total summation in terms of the number of pairwise comparisons 


14/04/24

- Forgot to remove the unusable samples from the full SOI TPM df
- Need to remove the samples and tissue/cancer types that do not need to be present in the analysis
 
- Would also like to repeat the cluster algorithm but using the number of clusters as the iterative parameter instead of the node height
- k instead of h 
- If the optimal cluster is the same or not between the two methods

 

15/04/24

- Edits to the clustering script to remove the samples that should not be included in the analysis based on their sample type

- Need to redefine the correlation clustering algorithm
- Maximise the sum of the intra-cluster correlation while minimising the sum of the inter-cluster correlation
- So the maximisation of the sum of the inter-cluster correlation minus the sum of the inter-cluster correlation

- Entire correlation clustering score, takes on 3 parts
- The Inter-cluster correlation score, Inter-CCS(to be minimised)
- The Intra-cluster correlation score, Intra-CCS (to be maximised)
- The Total-cluster correlation score, Total-CCS(to be maximised): Intra-CCS - Inter-CCS 

- For the Intra-CCS:
- The calculation is just the sum of the pairwise correlation coefficients of all the genes within the cluster
- Initial value = Set at 1 x The number of genes (each gene is its own cluster and therefore has an inner correlation of 1)
- Iterate over each node height, h or cluster, k
- For each iteration create the new clusters
- For each cluster:
	- create the expression-based correlation matrices using only the genes in the cluster 
	- calculate the average coefficient of the correlation matrix and save it
- Intra-CCS = Sum the averages 

At each step in the iteration:
- Consider the new cluster that was formed
- From the sum of the inter-cluster correlation, remove the correlation scores of genes/clusters that were removed (involved in the newest cluster)
- Add to the inter-cluster correlation, the correlation coefs generated as a result of the new cluster 
- For the intra-cluster correlations, for any cluster that has been affected, calculate the correlation coefs between the new gene(s) and the previous ones and add these coefs to the sum of the coefs that had been previously calculated
 

16/04/24

- Correlation clustering implementation continuation 

- Coded the Intra-CCS
- Need to code the Inter-CCS and the Total-CCS

- Redefining the clustering optimisation algo

- Coded in the Intra CCS Score
- Need to do the Inter-CCS score next
- Need to make sure to annotate the script correctly
- Might be helpful to put the scoring into a function instead of in the main script
- Need to figure out the actualf formula for the optimisation algo with the changes that are made to the inclusion of the unclustered genes in teh calculation
- Need to try to find the best values for lambda (penalty for the negtative values in the intra-CCS score), as well as for p and q (the powers that control the emphasis on poositive and negative correlations, can be different or the same)

- Tomorrow (Wednesday) start on the Inter score and on the presentation for monday


17/04/24

- Renaming the constituents of the cluster correlation scoring
- Intra-CCS to Intra Cluster Similarity Score, ICSS
- Inter-CCS to Inter Cluster Dissimilarity Score, ICDS

- Treating negative and positive correlations differently in terms of the dissimilarity is causing issues
- Modifying the scoring system such that it only considers the magnitude when assessing the dissimilarity between clusters and not the direction as well

- Edits to the ICSS so that it applies a sigmoid function in order to scale the correlations 
- Giving correlations above 0.7 a higher chance of being clustered


18/04/24

- Edits to the correlation clustering algorithm
- The sigmoid function intakes a midpoint threshold argument (set at 0.7) where the inflection point is located
- It also intakes a sensitivity argument which controls the degree to which a sigmoid affects the original r coef


- Try to find significant data on CBX1,3 or 5 for Aniek
- Think about how to cluster the CIN data

- After the selection of the optimal clustering it would be useful to know which genes get grouped together


19/04/24

- The optimisation algo that I have developed is a heuristic one as it does not find the exact solution but simplifies the task and finds the optimal solution given the conditions it is set
- finished running the clustering script and the algorithm 
- Generating the optimal clusters (12 clusters, 46 clustered genes, 281 unclustered genes)

- Making edits to the Presentation slides for Monday



20/04/24

- Presentation prep
 

21/04/24

- Included all Initial genes in the TCGA_Configuration script


22/04/24

- Project presentation Monday meeting

- Starting on the different CIN/Aberrant Features
 
- Adi provided the feedback document based on the presentation
- Would be useful to integrate the information from the feedback into future presentations
- Explain the terms clearly and simply
- Use graphs in the initial part of the presentation and guide the audience through them
- Give more details about the number of samples in the analysis and the references healthy/cancer or SOI/random set
- Explaining the cutoff selection
- Explanation on how the performance of the model can be affected by changes to the input parameters
 
- Reading up on the GLM and other multimodal classification models


23/04/24

- Collecting the data on CBX5/3/1, CHAF1A & EHMT2 for Aniek

- Finished the analysis for Aniek on the co-over/under expression of the 5 genes across multiple cancers
- Important to make sure to include the reference when doing comparative analyses like the above
- Need to point out exactly what is being compared to what (ex: gene expression in a healthy sample vs expression in certain condition, or, expression in 2 different conditions with neither being healthy)
 

24/04/24

- Considering multi-class vs multi-label vs multi-output classification models
 
- For the CIN features having to do with aneuploidy might be useful to parse the information into different categories: 
   - Numerical CIN: the numerical value of the gains/losses of full chromosomes (-2,-1,0,1,2) 
   - Structural CIN: categorical feature relating to the gain losses of specific chromosomal structures
 
- A multi-output classifier will be needed, likely a multi-label classifier specifically


25/04/24

- Actually the multi-class-multi-output classifier aka multitask one is the best solution 
- It is able to handle cases where the number properties (variables) and the number of classes (possible outcomes per property) are greater than 2
- Need to use the segmented data in order to determine the structural aneuploidy of the samples (arm loss)
- Need the segmented based log ratio cnv data to determine whole aneuploidy for the chromosomes as a whole (because need the info on the chromosomes as well as the loss/gain info)
- Not sure if i need the gene level CNV data yet
- Need to find a way of incorporating the arm loss/gain into the data 
- Should the analysis focus on different segments or on whole arms gained/lost as well


26/04/24

- found the Aneuploidy score file
- Shows the score as well as the arm specific gain/loss
- Only +1,0,-1 values in the gain/loss section
- Need to handle the null values
- Either reference the segment-based cnv file and use a measure from there
- Or assign them a value of 0 (no change in CN)
- The value given in the arm specific score is relative not absolute 
- Specifies a general gain or loss 
- will need to hot-encode each of the 3 possibilities for each arm of each chromosome
- each chromosome arm will represent a Property with the 3 possible values as the classes (multi-class)
- Should also use the chromosome segmental data for aneuploidies in specific segments

- The segmental data should be reduced beforehand getting rid of some of the 1700000 samples
- Filter to be set on the range between the start and end bases 
- Filter to be set on the logFC of the tumour/normal
- For the log filter values of -1 or less as well as +1 or more should be included

- Aniek wants the DGEA information for 2 additional genes CHAF1B and EHMT1
- Wants the focus to be on Ovarian cancer if possible


27/04/24

- Looking at the data of the DGEA for the ovarian samples 
- Looks like the samples for that cancer type are not paired

- the data from the PanCan studies in the TCGA dataset for ovarian cancer do not have any healthy control samples
- Will need to use another dataset for ovarian cancer samples

- Created the cvs & excel table for the complete gene list
- Need to find a dataset for ovarian cancer types with matching normal controls (couldn't find one) 


28/04/24 

- Converting the chromosome arm CNVs into the correct format (hot encoding)
- hot encoding the data may be a better method for logistic regression than maintaining the numerical values
- But maintaining the numerical values (-1,0,1) embeds the underlying relationship between the categories and may be beneficial for RFs and GBMs

- Remember that from your presentation last week that it was mentioned that i had a lot of mitotic genes in the over/under expressed genes in the volcano plot
- Look more into the genes that are shown in your plots
- Show the individual clusters and their makeup in a plot format as well
 
- Plotting the mds of the chromosome arm-level aneuploidies does not reveal anything too significant
- Will add in the Signature scores to see if they make a difference
- Including the individual hrd (loh, lst, Tai) scores as target features
- Removal of the total sum of the scores for now
- Most of these scores have to do with breast (BRCA1/2) affected cancer types, not sure they will be relevant in the determination of the rest of the cancer types


30/04/24

- Using the segmental copy number data will prove difficult
- The ranges in teh start and ending bps are not constant across all sample
- Therefore unlikely to be able to be used as an accurate measure of CIN across multiple samples


- Going to test multiple types of input RNAseq data
- The TPM values which will likely be the default
- And then refined normalised data for both within and across sample 

- Might add another type of RNAseq normalisation using the log2 Fold Change from the mean of all samples for said gene

- When formatting the RNAseq data for use dropping the metastatic cancer types from the analysis as well as the normal, and other types that are not explicitly human-patient based (i.e. cell lines, xenografts, unspecified samples...)
 

01/05/24

- the RNAseq data should also be mean centred using the mean of the each gene across the full sample set (training set)
- Mean entering the log values is the equivalent of calculating the log fold change between the value and the mean value
- Ultimately I should iterate over different input methods (types of normalisation if any) when running the model to see which method performs best (cross validation)
- First need to actually implement the model
 

02/05/24

- Generated the different types of expression inputs for the model to try in cross validation
- The different expression input sets that are finalised do not use clustering (dimensionality reduction) 
- Need to implement the dimensionality reduction method as well for all the different types (Expected counts, TPM, log transformed & library size scaled) 


03/05/24

- Initialising the script for the GBM model
- without the use fo the clustering dim reduction for now



04/05/24

- Reading up on the paper for my JC presentation


06/05/24

- In the model script making sure that the variables are in the right data type
 
- Going over some the genes that are in teh differential gene expression analysis that was done for Aniek
- Need to restrict the output to only the genes in the gene-set
 

07/05/24

- Need to go over the genes in the output for the DGEA and add a value column for the genes of interest

- Met with Marit about the het protein genes that she is looking into
- Would like some DGEA done on the set 

- Implementation of the train and test set for the model training


08/05/24

- JC prep 



09/05/24

- JC paper reading/prep


10/05/24

- Model building
- Need to apply cross validation so that it runs over all of the following:
   - RNAseq data type
   - eta, or learning rate parameter
   - max tree depth

- The best form of the RNAseq data seems to be the log transformed expected count data without scaling
- But need to perform the cross validation in combo with the other (hyper)parameters in order to determine for sure


11/05/24

- Thinking about a 10 fold cross validation for the GBM model training
- Need to figure out how to implement the model for multi-output with xgboost

 

12/05/24

- Likely going to need to implement a type of ensemble, chained or stacked model 
- For each of the different target types (continuous or categorical)
- Check Kaggle competitions and multi-output sklearn packages for a solution
 
- Would be nice to add the metrics that are assessed during the loops to a df and extract it in excel


14/05/24

- In the GBM script would be nice to check if the predicted aneuploidy score is better or worse than the addition of the the individual arm measurements

- or if the addition of the hrd metrics beat out the prediction of the overall HRD score
 
- The TPM measurements as opposed to the expected counts seem to perform best

- Except for the Aneuploidy score where the log expected counts seems to outperform the rest


15/05/24

- Lower learning rates seem to improve the model prediction 
- Prep for Thursday JC on the EpiSegMix paper


16/05/24

Meeting with Aniek:
- For the unformatted data
- Focus on the pericentromeric regions
- Try to define the start/end sequences that encompass the region and count the number of copy number aberrations that show up in the regions
- Can find the chromosome specific mappings by focusing on the proteins that bind to those regions and finding ChIP-seq data 
- Or can use the mappings for the centromere and combine that information for the edge regions of the euchromatin across the different chromosomes
- Check the Transposable elements and other types of elements that could be enriched in the region and might have been used as the basis for a ChIP-Seq experiment

- Start with finishing the modelling of the categorical based chromosome arm aneuploidies
- Then move on to trying to engineer a 'Pericentromeric cnv' feature

- Go over the data and the analysis for Marit this weekend


17/05/24

- Running the xgboost model on the arm level aneuploidy values independently 
- Trying out both a categorical model as well as a regression model
- Iterating over:
	- all the RNA seq datasets 
	- Values for gamma (0-4)
	- The depth level usually between (2-5)

Lower depth trees seem to outperform the higher depth ones 
As do lower levels of gamma 




18/05/24

- Need to initialise the GBM on the HpC

 

19/05/24

- Initialising the GBM script for use on the hpc 
- Creation and modification of the plots/graphs in the excel files

20/05/24

- Change of the measure of the model performance 
- From trying to assess the RSME to using the Accuracy
- Measure is able to be calculated for both the regression and the categorical models for all the features
- The accuracy so far (for the 1st chromosome) seems quite high



21/05/24

- Looking at the results of the different models in terms of Accuracy may be deceiving
- This is due to some of the classes being easier to identify than others
- Should break out the accuracy by class (+1, 0 and -1 for the aneuploidies) and maybe add in the TPR, FPR, and AUC
 
- Running the DGEA on the list of 6 proteins that Marit supplied
- Might also be good to run it on the fuller list that she included it

- For the GBM model, will likely have to be a stacked ensemble model
- With the first layer composed of all the target feature models
- The second layer composed of models for the same target features but using the output from the models in the first layer as the input for the models
 

22/05/24

- Run of the DGEA for Marit overnight on the hpc
- Spending the morning looking at the results of the tables a
- Making the charts (volcano plots) ...


- For the 6 of the genes that Marit 
- most do not show DGE in any of the cancer types
- Only SUV39H1/2 do on a few occasions
- Sent the graphs to the cancer_chromatin group 
- Did not send the tables which might be helpful


23/05/24 

- Need to implement CV for the different RNA sets
- and across the different depths
- and then the gammas once the RNAset/Depth has been set

- Once the base models which are all GBMs but regression for the hrd scores and then classification for the aneuploidy types are set
- Need to wrap them in based on the type
- Then implement an additional layer of meta models trained on the output from the base layer using CV
- The meta models will also be split into regression and classification based gbms


24/05/24

- Given that the classification GBMs continually outperform the regression ones for the prediction of the arm level aneuploidies only the classification ones will be considered for those tasks
- Given that the Scaled RNAseq data does not offer a constant outperformance in log-loss when used with gbm predictions for the arm level aneuploidies but requires significant resources (number of genes) in order to accurately assess the datatype could be beneficial to be dropped
- Chromosome 1q and 8p showed the lowest log-loss when using scaled data. But the improvement was very slight (~0.002 for 1q, and ~0.006 for 8p) which does not indicate a sufficient increase in performance to value the use of the data type (which requires increase processing). 
- Evaluating its use with the regression predictions for the hrd scores to determine whether the data processing step should be dropped entirely 


- Need to split the dataset up prior to the CV in order to have an unbiased and unseen test set

- Managed to enable multiprocessing for the gbm script on the local machine
- Need to implement it on the hpc server as well
- Doing the above using 60gb & 4 cpus
 for the regression model on the hrd scores, will need to standardise the data (mean scale)

Tired to run the multiprocessing and cross validation scripts on the hpc
- did not work due



25/05/24

- Rewriting the MP and CV gbm hyper-parameter tuning script 
- Writing a test one for both my machine and the hpc 

- Running the smaller test which worked on Mac does not appear ot work on the hpc
- Need to implement a process that generates each of the csv files as a separate job instead of using multi-thread/process from within the script


26/05/24

- hpc implementation is working
- Using multiple jobs via an array instead of the MP
- But need to change the tuning configuration

- Start by tuning just the depth, and then the rest

- also breaking out the rna set creation from the gbm model tuning
- the soi specific rna sets are created in a separate script and then accessed by the individual job scripts 
- instead of each job having to create the sets
 
- Need to check the row/column configuration of the rna sets
- Cannot tune the hyper-parameters on the full dataset
- Select a subset (8000/10000) of samples to use 
 

27/05/24

- Ran the depth tuning script on the cat and reg gbm scripts
- The scaled tpm rna sets seem to yield the best models (16/39) followed by log tpm (7/39) and then tpm (4/39)
- The best depth appears to be 1 (shallow model) 
 
- Depth of 1 (35/39) then 2 (3/39) followed by 3(1)
- Depths greater than 3 ( up to 10) never yielded the best model

- Set up excel macro to assess the individual tuning parameters for the categorical gbm
- Need to do the same for the regression one
- Need to better format the sheets that assess the minimum loss/RMSE for methods/supplemental docs

- out of the 10/39 chromosome arms whose model did not perform best while using a TPM rna set, 6/10's second best performing model used a TPM set, while 4/10 continued to see a better model using an Expected Counts set

- Met with Adi
- Need to figure out the segment based CNVs
- Using the T2T genome browser ucsc 
- Determine the pericentromeric regions 
- Their start-stop sites and then using the CNV data with threshold of 0.5 and -0.5 determine the number of CNVs within those regions 
- Or look at the regions that seem to display a large or smaller portion of cnv's

- Running the tuning for the gamma (leaf node regularisation) and the learning rate (eta, tree shrinkage factor) 
- eta running between 0.01 and 0.3 at a 0.05 step increase
- gamma at 0 to 0.1 at a 0.05 step increase

- Rerunning the script on the hpc for tuning the hyper-parameters
- Given the tree depth of 1 being optimal for the categorical gbm, I will be using a gamma value of 0 for those models 


28/05/24

- Running the hyper-parameter tuning for the reg and cat gbm models 

- Need to write up the Analyses that were done in the Inter genomic and tumour type analysis
- Need to write up the Analysis that were done in the creation of the metagenes
- Need to assess the use of the meta genes in the model vs the full gene set

- Finding a way to incorporate the segment based CNVs into the analysis 
- Looking at the ucsc genome browser with the T2T sequences in order to identify the regions that cover the pericentromeric regions
- Which will then be able to help get the ranges for this region on each of the chromosomes
- using the markers of Satellite repeats need to find out which ones are more specific to pericentromeric regions than the centromeric regions


- Using Human Satellite DNA (HSat1, HSat2 & HSat3) annotated regions as the regions defined as pericentromeric and
- Leaving out the other peri/centromeric annotations (censat, alphasat, betasat, gammasat and transition regions) as they don't seem to be as representative of pericentromeres as the HSat annotations


29/04/24

- For the continuous based target features  that use regression
- the GBM models perform best when using a log or log-scaled TPM data type
- The two are always the 2 best scoring for each of the features
- Will only consider those two 

- The best depth for the regression based trees is always 2
- Will only be using 2 depth for tuning for each of the continuous features

- When combining the directly adjacent regions within chromosomes themselves, this generates 181 different pericentromeric regions across all chromosomes
- 181 additional target features seems like too many to include in the model 
- This would add 2 * 181 targets to model for (due to the stacked nature of the model) 

- Seeing how many pericentromeric regions are generated when including ct (transitions regions) as annotations for pericentromeric regions
- Doing the above doesn't yield better results since the ct annotations cover transitions other than just between hsat annotations
- Going to group all the hsat regions within a single chromosome as a single pericentromeric region and verify via genome browser if this is mostly accurate or if they should be parsed into different groups
 
- Looking at the tuning results for the regression based trees (continuous target features)
- The best eta appears to be between 0.05 and 0.09

- Need to drop the Aneuploidy Score as well as the HRD scores
- These are just summations of the hrd related scores for the HRD score and the arm level aneuploidies for the Aneuploidy score
- They just add to the complexity of the model without revealing anything additional about the samples 
- Need to rewrite the regression based gbm modelling script without the extra targets


- In terms of defining the pericentromeric regions based on the hsat ranges and then combining these regions:
- Some chromosome are lacking in these types of satellites completely (6, 8, 11)
   - For chromosome 1 it adds up with the view of the sequences and other annotations on the genome browser


30/05/24

- Need to take a look at the different classes (loss, gain, neutral) in the aneuploidy CIN sets
- Determine if anything needs to be done about potential class imbalance

- Need to read up on the different satellites and verify that the ones that have been selected for are indeed pericentromeric 
- Which chromosomes they are found on and to what extent
- Whether the chromosomes that lack the satellite repeats still have pericentromeres
 
- Looking to integrate the beta and gamma satellites into the range for the pericentromeres
- When combining only adjacent ranges, this comes out to over 300 different pericentromeric sequences across all chromosomes
- This is too many for the model
- Thinking about combining all of these satellite regions that are separated by less than the main active HOR (Higher-Order Repeat) region 
- The HOR regions are part of the alpha satellites which bind to the kinetochores and are therefore labelled as centromeric regions
- Need to find the distance for these HOR regions for each of the chromosomes

- Need to find a way to define the cnvs in term of these regions

- need to separate the pericentromeric regions from active ribosomal gene regions
- Can't just combine HSat regions that don't have an active HOR region between them
- This is because there are some that have active gene regions within them 
- This is mainly seen in chromosome 13, 14, 15, 21, 22 & Y

- should not include censat or ct regions in the ranges as they tend to contain gene coding regions 

- Dilemma/Trade-off for defining the pericentromeric regions of use: 
	- When defining the regions in terms of adjacent HSat regions, end up with too many target features (> 300) which would increase the complexity of the model by 2x the number of additional target features
	- When combining the HSat ranges based on their location up/down-stream of the centromere (AlphaSat regions), this reduces the number of pericentromeric regions (and therefore target features) but the defined regions are less specific to heterochromatic regions and incorporate other genomic regions such as rDNA genes as well as transition regions and other centromeric satellites which show the presence of protein coding genes

- For each chromosome, thinking of selecting the longest contiguous pericentromeric region defined in terms of adjacent gbh regions which can be gapped by centromeric transition (ct) regions and any additional pericentromeric ranges that are beyond a certain threshold
- Thereby minimising the amount of rDNA & protein coding regions while ensuring the acquisition of the main pericentromeric regions from each chromosome

31/05/24


- Need to edit the pericentromeric ranges so that they do not start or end with a non-HSat region
- need to group by more than just the seqnames

- Grouping the segments by chromosome and adjacency and then removing the non-HSat regions at the beginning and end of the combined regions in order to ensure that the resuling pericentromeric region is mostly HSat related

the above yields 27 pericentromeric regions from 1 different chromosomes. The chromosomes that do not have any pericentromeric regions assigned to them include chromosomes 6,11, 12, 18 & 19, which seems to add up with what is seen in the genome viewer as well as what has been reported by Altmose (2022). The chromosomes which display more than a single elongated pericentromeric region include chromosomes:
- 13 with 3
- 15 with 2
- 16 with 2
- 21 with 2
- 22 with 4 
- Y with 2

- Now need to define the cnvs for each sample in terms of these regions


01/06/24

- Defined the pericentromeric regions of interest for each chromosome based on the T2T-CHM13v2 genome
- using the longest contiguous satellite repeat range that starts and ends in HSat but can be gapped by other types of satellites excluding alpha satellites (HOR, monomeric) 
- also using any additional ranges that meet the criteria above and exceed 1Mb in length

- Created the csv (metadata) file with the following information on the pericentromeric regions:
	- Peri_id: a unique pericentromeric identifier 
	- Chromosome: the chromosome
	- Start: starting bp
	- End: ending bp 
	- width: bp width
	- satellites: names of all the specific satellites within each region  

- Wondering about chromosome 23 in the tcga samples
- Does this represent chromosome X or X and/or Y 
- Should the chromosome information for that one be dropped? 

- Reconfigured the segmented cnv data into pericentromeric cnvs with the following approach: 
	- Identify regions corresponding to pericentromeric satellites (HSat, GSat, BSat, CT, CenSat) from the T2T data.
	- Combine adjacent regions to create contiguous pericentromeric regions.
	- Select the longest contiguous pericentromeric region and any additional regions beyond a 1Mb threshold.
	- Reconfigure the segmented copy number data based on the newly defined pericentromeric regions.
	- Calculate copy number variation (CNV) for each sample within the pericentromeric regions by proportionally allocating values based on overlap with segment boundaries.
	- Summarise CNV data in a wide format, with each pericentromeric region represented as a column and each sample as a row.

- This yielded an additional 15 target pericentromeric features which is lower than what I expected
- If I do not filter the data taking only the longest pericentromeric range & >1Mb segments, then it results in a total of 32 pericentromeric target features, which still might be manageable

- Need to add these peri_cnvs to the full CIN data 
- And then train the model on the data

02/06/24

- Merging the pericentromeric data to the other CIN data 
- Formatting the pericentromeric cnvs to 4 decimal places
- The pericentromeric CNV data is not thresholded (-1,0,1) but in a raw format that is the same as the original segmented data
- The range of the cnvs in the pericentromeric data goes from -1.9 to 2.8
- Plotting the mds of the samples in terms of the pericentromeric cnvs, nothing in particular that stood out

- Completed the pericentromeric features hyperparamter script tuning for the hpc 
- Initialise the run for the depth hyperparameters
- Will tune for the eta tomorrow with the gamma as well if needed (depth is greater than 1) 

03/05/24

- Running the pericentromeric feature tuning
- The best depth for each of the features came out to 1
- The best RNA data type seems to be more variable with 5 in contention
- Running for the learning rate 

- I may have to retrain the model due to a few issues:
   - The classes in the arm level aneuploidy features are not balanced 
   - The organisaiton of the samples when making the split may be biased, with certain cancer types being grouped in certain locaitons making the model prone to training on cdertain types while completely missing others
 

04/06/24

- Assessing the class imbalance in the data, specifically the arm level aneuploidies which have to be categorical (no continuous numerical value)
- Will likely have to deal with the imbalance using weights for each of the classes
- Higher weights for the under-sampled classes (1 & -1) vs the dominant class (0) 

 
- Also need to check that the order of the samples is not resulting in any bias
- And for good measure, should likely create the test and train set in a random fashion using seed(99) that is kept for all scripts so that the partion is the same
 
- Make sure that the scripts are handling NA tss codes without labelling them as na()

- Running the hpc tuning on all regression numerical data (HRD scores & pericnvs) for the updated data (split between train and test)
- Will need to figure out the weights for the classes before I can tune the aneuploidy arm factors


06/06/24

- edits to the pericentromeric script for the cnv mapping
- Checking on the number of cnv segments that are contributing to the weighted mean calculation by pericentromeric region and sample
- most >96% only have a single cnv contributing to the combined value

- Meeting with Aditya and Aniek: 
- Maybe be good to increase the pericentromeric regions to incorporate the inactive alpha satellite repeats as well 
- For Marit's plots, get the number of samples that show an increase/decrease in the expression of the genes
- Go for the stacked layer model in order to get the insights into the relationship between the target features as well as the genes

- Rerunning hte pericentromeric script to include alpha satellite repeats but exclude the active ones (true centromere) 
- The number of features comes out to 25 when limitinng based on gene length and 35 when disregarding this filter
- The number of relevant (mapped) features in the TCGA data comes out to 14 using the limited-length alpha included configuration
- The number of relevant (mapped) features in the TCGA data comes out to 22 using the unlimited alpha included configuration


07/06/24

- Re-running the hyper-parameter tuning for the pericentromeric features defined using the length-limited alpha included configuration

- Once the hpc is done running, need to remove the pericentromeric cnv hyperparameter files from the previous pericentromeric regions (defined without the alpha sat regions)

- Continuing the analysis for Marit's data
 
- Finished the volcano plots using the full 20 genes as well as the one that looks at the differential expreessioon and compares between and with other oncogenes
- Need to write up a bried methods section for how the analyses are performed and some of the facts/concerns about the plots or the analysis that might be useful for Marit to know
08/06/24

- Rerunnig the hyperparameter tuning
- Using the sets that fit the regression features the best from the previous output from the run (see the hyperparameters xls file)

- Using 10 fold cross validatioon with 50 round early stopage 
- Tuning the n_estimator which is a hyperparameter that tunes the number of trees in the models ranging from (50-350)
- Then tuning the max_depth with the depth ranging from 2-12


09/06/24

- The number of trees does not seem to greatly increase the performance, therefore selecting the n_estimators = 50 for all regression based models
- The performance of the models do not improve beyond a max depth of 5, therefore setting the max depth for all models to 5

- Tuning the learning rate (eta) using a range from 0.02 to 0.1 at increments of 0.02

- For the multiclass imbalanced class problem, I will have to use the sklearn compute class weight function in order to set the weights for the individual 3 classes 
- This only applies to the categorical aneuploidy models


10/06/24

- Making a short report for the analysis for Marit

- Tuning the min_child_weight
- the best performing models use the default value for min_child_weight of 1

- Finished the graphs for Marit's analysis
- Still need to get the absolute number of samples/idividuals that show a significant increase/decrease in expression in one or more of the heterochromatin genes by tissue/cancer11/06/24

- Tuning for Gamma which is the last hyperparameter to tune for in the regression based-base layer models

- For the Learning rate the best models occur on eta 0.02 and 0.04 will therefore select 0.03 

- For the thesis the story should focus on the biological question at hand (The LAD proteins and their contribution to CIN in cancer) and describe the model/pipeline as a tool for answering the question. 

- Try to get the pipeline to flow from the starting genes as input to the Feature importance of the genes as the output

- Plot some the training data over the rounds to see how the model performs/improves over iterations for the regression models and then the categorical models


 12/06/24

- Running the hyperparameter tuning again for the Trees (aka nrounds, n_estimators)
- This is since the number of trees = nrounds
- The value to save is not the number of rounds set !
- The value to save is the best occurring round aka the best iteration
- This value depends on the nrounds (max number of rounds) and any early stopping that is set
- For all the previous metrics that I saved I never knew the actual best occurring round i only saved the nrounds that were set
- For this running, i am using 50-10000 nrounds with an early stopping of 250 rounds and saving the best_iteration (round with best performing model) as the Tree hyperparameter value

- After 13 hours the runnings are encountering errors due to memory allocation, increasing the allocation from 3gb to 6gb 
- And the runtime is taking a very long time, will therefore decrease the number of folds for the Tree number hyperparamter (nrounds) from 10 to 5 
- Also increasing the time allocation from 18 to 20 hours


 13/06/24

-  Need to assign the weights to the classes in the categorical models

- Need to estimate the precision and accuracy of the categorical models using AUC 
- When doing this can use the One vs Rest (OvR) AUC metric, measuring the accuracy of the classification of a class (loss, gain or normal) as the positive class vs the other classes combined as the negative class
- Or could implement the One vs One (OvO) approach, which measures the accuracy of classifications for each possible pairwise combo (gain vs loss, loss vs normal, gain vs normal) and both ways (classifying gain vs normal is different than classifying normal vs gain) 
- When using the AUC eval metric with the multi:softprob objective in xgboost, the AUC is calculated using OvR 
- The AUC in the eval metric is the aggregate of each of the individual class AUC measurements weighing each by its prevalence in the dataset (this is only for the evaluation and not the training, still need to calculate the weights myself for that)

- Tuning the #trees is taking a while 


 14/06/24

- Think it would be nice to visualise the difference/improvement in the categorical models foo

- Curating the number of trees (nrounds) to use for training for each one of the variables
- using the max nround (rounded up to the closest hundred) of the 3 lowest RMSE associated iterations (excluding the iterations with NA for the number of rounds)
- Based on the CV for the regression-based models (see aneu_reg_xgb_metrics.xlsm and/or GBM_hyperparameters.xlsx)

- Forgot to set the seeds during cv 
- Validating the previous hyperparameteres using seed() 


15/06/24

- Validating the regression hyper-parameters using cv 
- Validation of the RNA_sets revealed some of them are indeed present when they were not previously (used cv with 10000 rounds 5 fold cv, 250 early stopping)
- Validating the # of trees as the numbers that showed for the RNA-set validation indicated that then nrounds should be less than what was estimated previously (100-7000 nround 5 fold cv,500 step size)
- Need to evaluate the predictions from the model not just ehe mlogloss that is output, so that I can generat the roc plot and AUC measures per class 
y_test <- as.integer(test_set[[feature]])
X_test <- test_set %>% select(-append("Row.names",colnames(full_cin)))
xgb_train <- xgb.DMatrix(data = as.matrix(X_train), label = y_train)
xgb_test <- xgb.DMatrix(data = as.matrix(X_test), label = y_test)
watchlist <- list(train = xgb_train, test = xgb_test)
for (depth in seq(1,10,2)){
cat(paste0("\n\t\t Depth: ", depth, "\n"))
# cat(paste0("\t\t Learning Rate: ", 0.04, "\n"))
for (gam in seq(1,2.5,1.25)){
cat(paste0("\t\t\t Gamma: ", gam))
xgb_params <- list(
booster = "gbtree",
max_depth = depth,
gamma = gam,
subsample = 0.75,
colsample_bytree = 1,
objective = "reg:squarederror",
eval_metric = "rmse",
eta = lr # Seems like the best eta is the closest one to 0
)
xgb_model <- xgb.train(
params = xgb_params,
data = xgb_train,
watchlist = watchlist,
early_stopping_rounds = 50,
nrounds = 6000,
verbose = 0
)
# xgb_model
# Best RMSE and iteration number
best_rmse <- min(xgb_model[["evaluation_log"]][["test_rmse"]])
xgb_preds <- predict(xgb_model, as.matrix(X_test), reshape = TRUE)
xgb_preds <- as.data.frame(xgb_preds)
xgb_preds <- xgb_preds %>%
rename(base_pred = "xgb_preds") %>%
mutate(mod_pred = round(base_pred),
actual = y_test,
correct = ifelse( mod_pred == actual, 1, 0)
)
aneu_reg_metrics_df <- rbind(aneu_reg_metrics_df,
data.frame(
RNA_Set = name,
Feature = feature,
Depth = depth,
Learning_Rate = lr,
Gamma = gam,
Accuracy =
sum(xgb$correct)/
length(xgb$correct)
)
)
}
}
}
write.csv(aneu_reg_metrics_df, paste0("Data/aneu_reg_xgb_metrics_params_",feature,"_",Sys.Date(), ".csv"))
}
rna_list <- list(
transcripts_per_million = tpm_set, # Seems to be the best performing
scalled_transcripts_per_million = scld_tpm_set, # not too useful (scalled)
log_scalled_transcripts_per_million = log_scld_tpm,
log_transcripts_per_million = log_tpm, # Best for Aneuploidy Score
expected_counts =exp_set,
scalled_expected_counts = scld_exp_set, # not too useful (scalled)
log_expected_counts = log_exp,
log_scalled_expected_counts = log_scld_exp # not too useful (scalled)
)
feature_list <- colnames(full_cin[1,6:15])
set.seed(35)
lr = 0.04
for (feature in feature_list){
cat(paste0("\n", feature, ":"))
aneu_reg_metrics_df <- data.frame(
RNA_Set = character(),
Feature = character(),
Depth = numeric(),
Learning_Rate = numeric(),
Gamma = numeric(),
Accuracy = numeric()
)
for (i in 1:length(rna_list)){
rna <- rna_list[[i]]
name <- names(rna_list)[i]
cat(paste0("\n\t", name, ": \n"))
full_df <- merge(rna, full_cin, by = "row.names")
sample_split <- sample.split(Y = full_df[colnames(full_cin)], SplitRatio = 0.7)
train_set <- subset(x = full_df, sample_split == TRUE)
test_set <- subset(x = full_df, sample_split == FALSE)
y_train <- as.integer(train_set[[feature]])
X_train <- train_set %>% select(-append("Row.names",colnames(full_cin)))
y_test <- as.integer(test_set[[feature]])
X_test <- test_set %>% select(-append("Row.names",colnames(full_cin)))
xgb_train <- xgb.DMatrix(data = as.matrix(X_train), label = y_train)
xgb_test <- xgb.DMatrix(data = as.matrix(X_test), label = y_test)
watchlist <- list(train = xgb_train, test = xgb_test)
for (depth in seq(1,10,2)){
cat(paste0("\n\t\t Depth: ", depth, "\n"))
# cat(paste0("\t\t Learning Rate: ", 0.04, "\n"))
for (gam in seq(1,2.5,1.25)){
cat(paste0("\t\t\t Gamma: ", gam))
xgb_params <- list(
booster = "gbtree",
max_depth = depth,
gamma = gam,
subsample = 0.75,
colsample_bytree = 1,
objective = "reg:squarederror",
eval_metric = "rmse",
eta = lr # Seems like the best eta is the closest one to 0
)
xgb_model <- xgb.train(
params = xgb_params,
data = xgb_train,
watchlist = watchlist,
early_stopping_rounds = 50,
nrounds = 6000,
verbose = 0
)
# xgb_model
# Best RMSE and iteration number
best_rmse <- min(xgb_model[["evaluation_log"]][["test_rmse"]])
xgb_preds <- predict(xgb_model, as.matrix(X_test), reshape = TRUE)
xgb_preds <- as.data.frame(xgb_preds)
xgb_preds <- xgb_preds %>%
rename(base_pred = "xgb_preds") %>%
mutate(mod_pred = round(base_pred),
actual = y_test,
correct = ifelse(mod_pred == actual, 1, 0)
)
aneu_reg_metrics_df <- rbind(aneu_reg_metrics_df,
data.frame(
RNA_Set = name,
Feature = feature,
Depth = depth,
Learning_Rate = lr,
Gamma = gam,
Accuracy =
sum(xgb_preds$correct)/
length(xgb_preds$correct)
)
)
}
}
}
write.csv(aneu_reg_metrics_df, paste0("Data/aneu_reg_xgb_metrics_params_",feature,"_",Sys.Date(), ".csv"))
}
rna_list <- list(
transcripts_per_million = tpm_set, # Seems to be the best performing
scalled_transcripts_per_million = scld_tpm_set, # not too useful (scalled)
log_scalled_transcripts_per_million = log_scld_tpm,
log_transcripts_per_million = log_tpm, # Best for Aneuploidy Score
expected_counts =exp_set,
scalled_expected_counts = scld_exp_set, # not too useful (scalled)
log_expected_counts = log_exp,
log_scalled_expected_counts = log_scld_exp # not too useful (scalled)
)
feature_list <- colnames(full_cin[1,13:15])
set.seed(35)
lr = 0.04
for (feature in feature_list){
cat(paste0("\n", feature, ":"))
aneu_reg_metrics_df <- data.frame(
RNA_Set = character(),
Feature = character(),
Depth = numeric(),
Learning_Rate = numeric(),
Gamma = numeric(),
Accuracy = numeric()
)
for (i in 4:length(rna_list)){
rna <- rna_list[[i]]
name <- names(rna_list)[i]
cat(paste0("\n\t", name, ": \n"))
full_df <- merge(rna, full_cin, by = "row.names")
sample_split <- sample.split(Y = full_df[colnames(full_cin)], SplitRatio = 0.7)
train_set <- subset(x = full_df, sample_split == TRUE)
test_set <- subset(x = full_df, sample_split == FALSE)
y_train <- as.integer(train_set[[feature]])
X_train <- train_set %>% select(-append("Row.names",colnames(full_cin)))
y_test <- as.integer(test_set[[feature]])
X_test <- test_set %>% select(-append("Row.names",colnames(full_cin)))
xgb_train <- xgb.DMatrix(data = as.matrix(X_train), label = y_train)
xgb_test <- xgb.DMatrix(data = as.matrix(X_test), label = y_test)
watchlist <- list(train = xgb_train, test = xgb_test)
for (depth in seq(1,10,9)){
cat(paste0("\n\t\t Depth: ", depth, "\n"))
# cat(paste0("\t\t Learning Rate: ", 0.04, "\n"))
for (gam in seq(1,2.5,1.25)){
cat(paste0("\t\t\t Gamma: ", gam))
xgb_params <- list(
booster = "gbtree",
max_depth = depth,
gamma = gam,
subsample = 0.75,
colsample_bytree = 1,
objective = "reg:squarederror",
eval_metric = "rmse",
eta = lr # Seems like the best eta is the closest one to 0
)
xgb_model <- xgb.train(
params = xgb_params,
data = xgb_train,
watchlist = watchlist,
early_stopping_rounds = 50,
nrounds = 6000,
verbose = 0
)
# xgb_model
# Best RMSE and iteration number
best_rmse <- min(xgb_model[["evaluation_log"]][["test_rmse"]])
xgb_preds <- predict(xgb_model, as.matrix(X_test), reshape = TRUE)
xgb_preds <- as.data.frame(xgb_preds)
xgb_preds <- xgb_preds %>%
rename(base_pred = "xgb_preds") %>%
mutate(mod_pred = round(base_pred),
actual = y_test,
correct = ifelse(mod_pred == actual, 1, 0)
)
aneu_reg_metrics_df <- rbind(aneu_reg_metrics_df,
data.frame(
RNA_Set = name,
Feature = feature,
Depth = depth,
Learning_Rate = lr,
Gamma = gam,
Accuracy =
sum(xgb_preds$correct)/
length(xgb_preds$correct)
)
)
}
}
}
write.csv(aneu_reg_metrics_df, paste0("Data/aneu_reg_xgb_metrics_params_",feature,"_",Sys.Date(), ".csv"))
}
rna_list <- list(
transcripts_per_million = tpm_set, # Seems to be the best performing
scalled_transcripts_per_million = scld_tpm_set, # not too useful (scalled)
log_scalled_transcripts_per_million = log_scld_tpm,
log_transcripts_per_million = log_tpm,
expected_counts = exp_set,
scalled_expected_counts = scld_exp_set,
log_expected_counts = log_exp,
log_scalled_expected_counts = log_scld_exp
)
# aneu_feature_list <- colnames(full_cin[1,6:length(full_cin)])
aneu_feature_list <- colnames(full_cin[1,6:8])
aneu_cat_metrics_df <- data.frame(
RNA_Set = character(),
Feature = character(),
Depth = numeric(),
Learning_Rate = numeric(),
Gamma = numeric(),
Accuracy = numeric()
)
lr= 0.04
set.seed(33)
for (feature in aneu_feature_list){
cat(paste0("\n", feature, ":"))
for (i in 6:length(rna_list)){
rna <- rna_list[[i]]
name <- names(rna_list)[i]
cat(paste0("\n\t", name, ":"))
full_df <- merge(rna, full_cin, by = "row.names")
sample_split <- sample.split(Y = full_df[colnames(full_cin)], SplitRatio = 0.7)
train_set <- subset(x = full_df, sample_split == TRUE)
test_set <- subset(x = full_df, sample_split == FALSE)
y_train <- as.integer(train_set[[feature]])
X_train <- train_set %>% select(-append("Row.names",colnames(full_cin)))
y_test <- as.integer(test_set[[feature]])
X_test <- test_set %>% select(-append("Row.names",colnames(full_cin)))
y_train[y_train == -1] <- 0
y_train[y_train == 1] <- 2
y_train[y_train == 0] <- 1
y_test[y_test == -1] <- 0
y_test[y_test == 1] <- 2
y_test[y_test == 0] <- 1
xgb_train <- xgb.DMatrix(data = as.matrix(X_train), label = y_train)
xgb_test <- xgb.DMatrix(data = as.matrix(X_test), label = y_test)
watchlist <- list(train = xgb_train, test = xgb_test)
for (depth in seq(1,8,4)){
cat(paste0("\n\t\t Depth: ", depth, "\n"))
for (gam in seq(1,2.5,2)) {
cat(paste0("\t\t\t Gamma: ", gam))
xgb_params <- list(
booster = "gbtree",
num_class=3,
max_depth = depth,
gamma = gam,
subsample = 0.75,
colsample_bytree = 1,
objective = "multi:softmax",
eval_metric = "mlogloss",
eta = 0.04 # Seems like the best eta is the closest one to 0
)
xgb_model <- xgb.train(
params = xgb_params,
data = xgb_train,
watchlist = watchlist,
early_stopping_rounds = 50,
nrounds = 6000,
verbose = 0
)
# Best loss and iteration number
best_loss <- min(xgb_model[["evaluation_log"]][["test_mlogloss"]])
xgb_cat_preds <- predict(xgb_model, as.matrix(X_test), reshape = TRUE)
xgb_cat_preds <- as.data.frame(xgb_cat_preds)
xgb_cat_preds <- xgb_cat_preds %>%
rename(pred = "xgb_cat_preds") %>%
mutate(actual = y_test,
correct = ifelse(pred == actual, 1, 0)
)
aneu_cat_metrics_df <- rbind(aneu_cat_metrics_df,
data.frame(
RNA_Set = name,
Feature = feature,
Depth = depth,
Learning_Rate = lr,
Gamma = gam,
Accuracy =
sum(xgb_cat_preds$correct)/
length(xgb_cat_preds$correct)
)
)
}
}
}
write.csv(aneu_cat_metrics_df, paste0("Data/aneu_cat_xgb_metrics_params_",feature,"_",Sys.Date(), ".csv"))
}
rna_list <- list(
transcripts_per_million = tpm_set, # Seems to be the best performing
scalled_transcripts_per_million = scld_tpm_set, # not too useful (scalled)
log_scalled_transcripts_per_million = log_scld_tpm,
log_transcripts_per_million = log_tpm, # Best for Aneuploidy Score
expected_counts =exp_set,
scalled_expected_counts = scld_exp_set, # not too useful (scalled)
log_expected_counts = log_exp,
log_scalled_expected_counts = log_scld_exp # not too useful (scalled)
)
reg_feature_list <- colnames(full_cin[1,6:12])
set.seed(35)
lr = 0.04
for (feature in reg_feature_list){
cat(paste0("\n", feature, ":"))
aneu_reg_metrics_df <- data.frame(
RNA_Set = character(),
Feature = character(),
Depth = numeric(),
Learning_Rate = numeric(),
Gamma = numeric(),
Accuracy = numeric()
)
for (i in 1:length(rna_list)){
rna <- rna_list[[i]]
name <- names(rna_list)[i]
cat(paste0("\n\t", name, ": \n"))
full_df <- merge(rna, full_cin, by = "row.names")
sample_split <- sample.split(Y = full_df[colnames(full_cin)], SplitRatio = 0.7)
train_set <- subset(x = full_df, sample_split == TRUE)
test_set <- subset(x = full_df, sample_split == FALSE)
y_train <- as.integer(train_set[[feature]])
X_train <- train_set %>% select(-append("Row.names",colnames(full_cin)))
y_test <- as.integer(test_set[[feature]])
X_test <- test_set %>% select(-append("Row.names",colnames(full_cin)))
xgb_train <- xgb.DMatrix(data = as.matrix(X_train), label = y_train)
xgb_test <- xgb.DMatrix(data = as.matrix(X_test), label = y_test)
watchlist <- list(train = xgb_train, test = xgb_test)
for (depth in seq(1,10,2)){
cat(paste0("\n\t\t Depth: ", depth, "\n"))
# cat(paste0("\t\t Learning Rate: ", 0.04, "\n"))
for (gam in seq(1,3.5)){
cat(paste0("\t\t\t Gamma: ", gam))
xgb_params <- list(
booster = "gbtree",
max_depth = depth,
gamma = gam,
subsample = 0.75,
colsample_bytree = 1,
objective = "reg:squarederror",
eval_metric = "rmse",
eta = lr # Seems like the best eta is the closest one to 0
)
xgb_model <- xgb.train(
params = xgb_params,
data = xgb_train,
watchlist = watchlist,
early_stopping_rounds = 50,
nrounds = 6000,
verbose = 0
)
# xgb_model
# Best RMSE and iteration number
best_rmse <- min(xgb_model[["evaluation_log"]][["test_rmse"]])
xgb_preds <- predict(xgb_model, as.matrix(X_test), reshape = TRUE)
xgb_preds <- as.data.frame(xgb_preds)
xgb_preds <- xgb_preds %>%
rename(base_pred = "xgb_preds") %>%
mutate(mod_pred = round(base_pred),
actual = y_test,
correct = ifelse(mod_pred == actual, 1, 0)
)
aneu_reg_metrics_df <- rbind(aneu_reg_metrics_df,
data.frame(
RNA_Set = name,
Feature = feature,
Depth = depth,
Learning_Rate = lr,
Gamma = gam,
Accuracy =
sum(xgb_preds$correct)/
length(xgb_preds$correct)
)
)
}
}
}
write.csv(aneu_reg_metrics_df, paste0("Data/aneu_reg_xgb_metrics_params_",feature,"_",Sys.Date(), ".csv"))
}
rna_list <- list(
transcripts_per_million = tpm_set, # Seems to be the best performing
scalled_transcripts_per_million = scld_tpm_set, # not too useful (scalled)
log_scalled_transcripts_per_million = log_scld_tpm,
log_transcripts_per_million = log_tpm,
expected_counts = exp_set,
scalled_expected_counts = scld_exp_set,
log_expected_counts = log_exp,
log_scalled_expected_counts = log_scld_exp
)
# aneu_feature_list <- colnames(full_cin[1,6:length(full_cin)])
aneu_feature_list <- colnames(full_cin[1,6:12])
aneu_cat_metrics_df <- data.frame(
RNA_Set = character(),
Feature = character(),
Depth = numeric(),
Learning_Rate = numeric(),
Gamma = numeric(),
Accuracy = numeric()
)
lr= 0.04
set.seed(33)
for (feature in aneu_feature_list){
cat(paste0("\n", feature, ":"))
for (i in 1:length(rna_list)){
rna <- rna_list[[i]]
name <- names(rna_list)[i]
cat(paste0("\n\t", name, ":"))
full_df <- merge(rna, full_cin, by = "row.names")
sample_split <- sample.split(Y = full_df[colnames(full_cin)], SplitRatio = 0.7)
train_set <- subset(x = full_df, sample_split == TRUE)
test_set <- subset(x = full_df, sample_split == FALSE)
y_train <- as.integer(train_set[[feature]])
X_train <- train_set %>% select(-append("Row.names",colnames(full_cin)))
y_test <- as.integer(test_set[[feature]])
X_test <- test_set %>% select(-append("Row.names",colnames(full_cin)))
y_train[y_train == -1] <- 0
y_train[y_train == 1] <- 2
y_train[y_train == 0] <- 1
y_test[y_test == -1] <- 0
y_test[y_test == 1] <- 2
y_test[y_test == 0] <- 1
xgb_train <- xgb.DMatrix(data = as.matrix(X_train), label = y_train)
xgb_test <- xgb.DMatrix(data = as.matrix(X_test), label = y_test)
watchlist <- list(train = xgb_train, test = xgb_test)
for (depth in seq(1,10,2)){
cat(paste0("\n\t\t Depth: ", depth, "\n"))
for (gam in seq(1,3.5)) {
cat(paste0("\t\t\t Gamma: ", gam))
xgb_params <- list(
booster = "gbtree",
num_class=3,
max_depth = depth,
gamma = gam,
subsample = 0.75,
colsample_bytree = 1,
objective = "multi:softmax",
eval_metric = "mlogloss",
eta = 0.04 # Seems like the best eta is the closest one to 0
)
xgb_model <- xgb.train(
params = xgb_params,
data = xgb_train,
watchlist = watchlist,
early_stopping_rounds = 50,
nrounds = 6000,
verbose = 0
)
# Best loss and iteration number
best_loss <- min(xgb_model[["evaluation_log"]][["test_mlogloss"]])
xgb_cat_preds <- predict(xgb_model, as.matrix(X_test), reshape = TRUE)
xgb_cat_preds <- as.data.frame(xgb_cat_preds)
xgb_cat_preds <- xgb_cat_preds %>%
rename(pred = "xgb_cat_preds") %>%
mutate(actual = y_test,
correct = ifelse(pred == actual, 1, 0)
)
aneu_cat_metrics_df <- rbind(aneu_cat_metrics_df,
data.frame(
RNA_Set = name,
Feature = feature,
Depth = depth,
Learning_Rate = lr,
Gamma = gam,
Accuracy =
sum(xgb_cat_preds$correct)/
length(xgb_cat_preds$correct)
)
)
}
}
}
write.csv(aneu_cat_metrics_df, paste0("Data/aneu_cat_xgb_metrics_params_",feature,"_",Sys.Date(), ".csv"))
}
source("~/.active-rstudio-document")

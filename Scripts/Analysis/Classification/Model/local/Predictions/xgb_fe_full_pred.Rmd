---
title: "XGB full prediction"
output: html_document
date: "2024-06-27"
note: "This file is intended to be used for the full prediction of the XGB model 
from the soi RNAseq data to the final predictions from the meta learners"
---
```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = "/Users/Dyll/Documents/Education/VU_UVA/Internship/Epigenetics/Janssen_Group-UMCUtrecht/Main_Project")
```


```{r}
# Load the packages
library(dplyr)
library(readr)
library(tidyverse)
library(xgboost)
library(caret)
library(ggplot2)
```


```{r}
print_every <- 100
early_stop <- 25


# setwd("/Users/Dyll/Documents/Education/VU_UVA/Internship/Epigenetics/Janssen_Group-UMCUtrecht/Main_Project")

input_path <- "Data/Gen_Model_input/"
```

FUNCTIONS
```{r}
# Load the functions
# Function to map factor levels to weights
feature_digit_function <- function(factors) {
  sapply(factors, function(x) selected_weights[as.numeric(x)])
}

# Function to extract the fold indices from the folds
combine_all_folds <- function(folds) {
  all_indices <- c()
  for (fold in folds) {
    all_indices <- c(all_indices, fold)
  }
  return(all_indices)
}

# Function to calculate the confusion matrix using the caret package and return the confusion matrix object
calculate_confusion_matrix <- function(predictions_df, predicted_col, true_col) {
  # Ensure the input columns exist in the predictions dataframe
  if (!predicted_col %in% names(predictions_df) || !true_col %in% names(predictions_df)) {
    stop("Specified columns do not exist in the provided dataframe")
  }

  # Create the confusion matrix
  cm <- confusionMatrix(
    data = factor(predictions_df[[predicted_col]], levels = c(-1, 0, 1)),
    reference = factor(predictions_df[[true_col]], levels = c(-1, 0, 1))
  )

  # Return the confusion matrix object
  return(cm)
}

# Function to extract the true positive rate from the confusion matrix and create the heatmap
tpr_confusion_matrix <- function(object, feature, learner_type) {
  new_table <- pivot_wider(as.data.frame(object$table), names_from = Reference, values_from = Freq, values_fill = list(frequency = 0)) %>%
    column_to_rownames("Prediction") %>%
    sweep(., 2, colSums(.), "/") %>%
    round(., 2) %>%
    rownames_to_column("Prediction") %>%
    pivot_longer(., cols = -Prediction, names_to = "Reference", values_to = "TPR") %>%
    mutate(TPR = round(TPR, 2))

  graph <- ggplot(new_table, aes(x = Reference, y = Prediction, fill = TPR)) +
    geom_tile() +
    geom_text(aes(label = TPR), vjust = 1) +
    scale_fill_gradient(
      low = "#FFEBEE", high = "#B71C1C",
      limits = c(0, 1)
    ) +
    theme_minimal() +
    labs(
      title = paste0(
        learner_type,
        " Learner Performance for ",
        feature
      ),
      x = "Actual Class",
      y = "Predicted Class"
    ) +
    theme(
      axis.text.x = element_text(hjust = 1), # Adjust text angle for better legibility
      plot.title = element_text(hjust = 0.5),
      legend.title = element_blank()
    )

  # save the plot
  filefold <- file.path("Plots/Model_Plots/General_model/Results/Categorical/Confusion_matrices")
  if (!dir.exists(filefold)) {
    dir.create(filefold, recursive = TRUE)
  }

  # Save the heatmap
  ggsave(
    filename = paste0(
      filefold,
      feature, "_",
      learner_type,
      "_TPR_Heatmap.png"
    ),
    plot = graph,
    width = 10,
    height = 10
  )
}

# Function to get the stats from the confusion matrix object
create_confusion_matrix_data <- function(obj, type) {
  as.data.frame(obj$byClass) %>%
    rownames_to_column("Class") %>%
    mutate(Type = type) %>%
    select(-c(
      "Pos Pred Value", "Neg Pred Value",
      "Prevalence", "Detection Rate",
      "Detection Prevalence", "Sensitivity"
    )) %>%
    pivot_longer(cols = -c(Type, Class), names_to = "Metric", values_to = "Value") %>%
    as.data.frame()
}


# Function to create the plot based on the confusion matrix stats by learner type
confusion_stat_plot <- function(data) {
  Feature <- data$Feature[1]

  metrics_plt <- data %>%
    ggplot(aes(x = factor(Metric, levels = rev(c(
      "Balanced Accuracy", "F1", "Precision",
      "Recall", "Specificity"
    ))), y = Value, fill = Type)) +
    geom_bar(stat = "identity", position = "dodge") +
    coord_flip() +
    scale_fill_manual(values = c("#ABDDDE", "#CCEDB1", "#41B7C4")) +
    facet_wrap(~Class) +
    theme_minimal() +
    labs(
      title = paste0("Model Performance Stats for ", Feature),
      x = "Class",
      y = "Value"
    ) +
    scale_y_continuous(breaks = seq(0, 1, by = 0.25)) +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1),
      axis.text.y = element_text(size = 10, face = "bold"),
      plot.title = element_text(hjust = 0.5),
      panel.grid.major.x = element_line(
        colour = "grey",
        linetype = 2
      ),
      panel.grid.major.y = element_blank(),
      panel.grid.minor.x = element_blank(),
      panel.spacing = unit(4, "lines")
    )

  # save the plot
  filefold <- file.path("Plots/Model_Plots/General_model/Results/Categorical/Stat_metrics")
  if (!dir.exists(filefold)) {
    dir.create(filefold, recursive = TRUE)
  }

  ggsave(
    filename = file.path(filefold, paste0(
      Feature,
      "_Stats.pdf"
    )),
    plot = metrics_plt,
    width = 10,
    height = 10
  )
}
```

RNA SETS
```{r}
# Set the constant variables
# The RNA list
rna_list <- list(
  transcripts_per_million = "tpm",
  scaled_transcripts_per_million = "scld_tpm",
  log_scaled_transcripts_per_million = "log_scld_tpm",
  log_transcripts_per_million = "log_tpm",
  expected_counts = "exp",
  scaled_expected_counts = "scld",
  log_expected_counts = "log",
  log_scaled_expected_counts = "log_scld"
)
```

RESPONSE FEATURES
```{r}
# The CIN response features
# Categorical features
cat_cin <- read_tsv(
  paste0(
    input_path,
    "CIN_Features/PANCAN_ArmCallsAndAneuploidyScore_092817.txt"
  ),
  show_col_types = FALSE
) %>%
  replace(is.na(.), 0) %>%
  select(-c("Type", "Aneuploidy Score")) %>%
  mutate(Sample = str_replace_all(Sample, "-", "\\.")) %>%
  column_to_rownames("Sample") %>%
  mutate_all(~ replace(., . == 1, 2)) %>%
  mutate_all(~ replace(., . == 0, 1)) %>%
  mutate_all(~ replace(., . == -1, 0)) %>%
  rename(
    "13q" = "13 (13q)",
    "14q" = "14 (14q)",
    "15q" = "15 (15q)",
    "21q" = "21 (21q)",
    "22q" = "22 (22q)"
  )

cat("\n Categorical CIN:  \n")
print(head(cat_cin[20:30]))

# Numerical features
# HRD scores
ori_hrd <- read_tsv(
  paste0(input_path, "CIN_Features/TCGA.HRD_withSampleID.txt"),
  show_col_types = FALSE
)

t_hrd <- as.data.frame(t(ori_hrd))
first_hrd <- t_hrd
colnames(first_hrd) <- t_hrd[1, ]
hrd <- as.data.frame(first_hrd[-1, ]) %>%
  mutate_all(as.numeric) %>%
  rename(loh_hrd = "hrd-loh") %>%
  select(-HRD) %>%
  mutate(new = str_replace_all(rownames(.), "-", "\\."))

rm(first_hrd)
rm(ori_hrd)
rm(t_hrd)

rownames(hrd) <- hrd$new
hrd <- hrd %>%
  select(-new)

# print(head(hrd))

# Pericentromeric CNVs
peri_cnv <- read.csv(
  paste0(
    input_path,
    "/CIN_Features/lim_alpha_incl_TCGA_pericentro.csv"
  )
) %>%
  mutate_all(~ replace(., is.na(.), 0)) %>%
  mutate(sampleID = gsub("-", ".", sampleID)) %>%
  column_to_rownames("sampleID")

# print(dim(peri_cnv))
```

HYPERPARAMETERS
```{r}
base_cat_parameters <- read.csv(
  paste0(
    input_path,
    "Hyperparameters/base_cat_hyperparams.csv"
  )
)
base_reg_parameters <- read.csv(
  paste0(
    input_path,
    "Hyperparameters/base_reg_hyperparams.csv"
  )
)

meta_parameters <- read.csv(
  paste0(
    input_path,
    "Hyperparameters/meta_hyperparams.csv"
  )
)
```

FULL CIN DF
```{r}
reg_cin <- merge(
  hrd,
  peri_cnv,
  by = "row.names"
) %>%
  mutate(Row.names = str_replace_all(Row.names, "-", ".")) %>%
  column_to_rownames("Row.names")
cat("\n Regression CIN:  \n")
print(head(reg_cin[1:5]))

# rm(peri_cnv)
# rm(hrd)

full_cin <- merge(
  cat_cin,
  reg_cin,
  by = "row.names"
) %>%
  column_to_rownames("Row.names")
cat("\n Full CIN:  \n")
print(head(full_cin[1:5]))

# All response feature names
response_features <- colnames(full_cin)
reg_features <- colnames(reg_cin)
cat_features <- colnames(cat_cin)
cat(
  "\n Response Features # :", length(response_features), "\n",
  "Regression Features # :", length(reg_features), "\n",
  "Categorical Features # :", length(cat_features), "\n"
)

# rm(reg_cin)
# rm(cat_cin)
```

FOLDS
```{r}
# Create the folds to be used

# Create the full data by merging the soi & cancerous RNA data with the CIN data
full_data <- merge(
  read.csv(
    paste0(
      input_path,
      "RNA/Train/train_tpm_soi.csv"
    ),
    row.names = 1
  ),
  full_cin,
  by = "row.names"
)

cat("\n Full Data:  \n")
print(head(full_data[1:5]))

# Creating the folds and returning the indices for the out-of-fold predictions only
folds <- createFolds(full_data[["1p"]], k = 2, list = TRUE, returnTrain = FALSE)
cat("\n Folds # :", length(folds), "\n")

# Create the empty dataframe that will store the out-of-fold predictions for each model
base_oof_predictions <- data.frame(
  matrix(
    ncol = length(response_features),
    nrow = length(combine_all_folds(folds))
  )
)
colnames(base_oof_predictions) <- paste0("pred_", response_features)

cat("\n Predictions Dataframe:  \n")
print(head(base_oof_predictions[1:5]))
```

LABELS
```{r}
# Get the actual (true) fold labels
labels <- full_data %>%
  select(all_of(intersect(response_features, colnames(.)))) %>%
  mutate(
    index = as.factor(row_number())
  ) %>%
  rename_with(~ paste0("act_", .))

# merge the fold labels with the empty predictions dataframe
# making sure to keep the order of the original indices
base_oof_predictions <- cbind(base_oof_predictions, labels) %>%
  arrange(act_index)
```

BASE TRAINING
```{r}
# Create the full feature importance dataframe
full_feature_imp_df <- data.frame()

for (feature in response_features) {
  cat(
    "Feature: ", feature, "\n\n"
  )

  if (feature %in% cat_features) {
    # Get the parameters from stored Parameters file
    parameters <- base_cat_parameters

    # select the parameters and weights corresponding to the index
    selected_parameters <- parameters[parameters$Feature == feature, ]

    selected_feature <- selected_parameters$Feature
    selected_rna_set <- selected_parameters$RNA_set
    selected_trees <- as.numeric(selected_parameters$Trees)
    selected_eta <- selected_parameters$Eta
    selected_gamma <- selected_parameters$Gamma
    selected_max_depth <- selected_parameters$Max_depth
    selected_min_child <- selected_parameters$Child_weight
    selected_weights <- as.numeric(
      selected_parameters[c(
        "Weight_loss",
        "Weight_normal",
        "Weight_gain"
      )]
    )

    cat(
      "\n Selected Parameters: \n",
      "Feature: ", selected_feature, "\t",
      "RNA Set: ", selected_rna_set, "\t",
      "Trees: ", selected_trees, "\n",
      "Eta: ", selected_eta, "\t",
      "Gamma: ", selected_gamma, "\t",
      "Max Depth: ", selected_max_depth, "\t",
      "Weights: ", selected_weights, "\t",
      "Min Child: ", selected_min_child, "\n"
    )

    rna_selection_name <- rna_list[[selected_rna_set]]
    rna_set <- read.csv(
      paste0(
        input_path,
        "RNA/Train/train_",
        rna_selection_name,
        "_soi.csv"
      ),
      row.names = 1
    )

    full_df <- merge(rna_set,
      full_cin,
      by = "row.names"
    )

    y <- as.integer(full_df[[selected_feature]])
    X <- full_df %>% select(-c("Row.names", all_of(response_features)))

    # Create the out-of-fold predictions column
    oof_predictions <- numeric(nrow(X))

    # Create df to store the importance matrix
    feature_imp_df <- data.frame()

    # Fold-wise training
    for (fold_index in seq_along(folds)) {
      cat(
        "Fold: ", fold_index, "\n"
      )
      train_indices <- setdiff(seq_len(nrow(full_df)), folds[[fold_index]])
      valid_indices <- folds[[fold_index]]

      train_data <- xgb.DMatrix(data = as.matrix(X[train_indices, ]), label = y[train_indices])
      valid_data <- xgb.DMatrix(data = as.matrix(X[valid_indices, ]), label = y[valid_indices])


      train_y_factor <- factor(y[train_indices], levels = c(0, 1, 2))
      weights <- as.numeric(feature_digit_function(train_y_factor))
      setinfo(train_data, "weight", weights)

      xgb_model <- xgb.train(
        data = train_data,
        nrounds = selected_trees,
        objective = "multi:softmax",
        eval_metric = "mlogloss",
        max_depth = selected_max_depth,
        min_child_weight = selected_min_child,
        early_stopping_rounds = early_stop,
        eta = selected_eta,
        gamma = selected_gamma,
        watchlist = list(eval = valid_data),
        num_class = 3,
        print_every_n = print_every,
      )

      # Store OOF predictions
      oof_predictions[valid_indices] <- predict(xgb_model, valid_data)

      # Create the feature importance matrix
      importance_matrix <- xgb.importance(feature_names = colnames(X), model = xgb_model)

      # Store the importance matrix in the dataframe
      feature_imp_df <- rbind(feature_imp_df, as.data.frame(importance_matrix))
    }

    # Store the predictions in the corresponding column
    base_oof_predictions[[paste0("pred_", selected_feature)]] <- oof_predictions
  } else if (feature %in% reg_features) {
    # Get the parameters from stored Parameters file
    parameters <- base_reg_parameters

    # select the parameters and weights corresponding to the index
    selected_parameters <- parameters[parameters$Feature == feature, ]

    selected_feature <- selected_parameters$Feature
    selected_rna_set <- selected_parameters$RNA_set
    selected_trees <- as.numeric(selected_parameters$Trees)
    selected_eta <- selected_parameters$Eta
    selected_gamma <- selected_parameters$Gamma
    selected_max_depth <- selected_parameters$Max_depth
    selected_min_child <- selected_parameters$Child_weight

    cat(
      "\n Selected Parameters: \n",
      "Feature: ", selected_feature, "\t",
      "RNA Set: ", selected_rna_set, "\t",
      "Trees: ", selected_trees, "\n",
      "Eta: ", selected_eta, "\t",
      "Gamma: ", selected_gamma, "\t",
      "Max Depth: ", selected_max_depth, "\t",
      "Min Child: ", selected_min_child, "\n"
    )

    rna_selection_name <- rna_list[[selected_rna_set]]
    rna_set <- read.csv(
      paste0(
        input_path,
        "RNA/Train/train_",
        rna_selection_name,
        "_soi.csv"
      ),
      row.names = 1
    )

    full_df <- merge(rna_set,
      full_cin,
      by = "row.names"
    )

    y <- as.numeric(full_df[[selected_feature]])
    X <- full_df %>% select(-c("Row.names", all_of(response_features)))

    # Create the out-of-fold predictions column
    oof_predictions <- numeric(nrow(X))

    # Create df to store the importance matrix
    feature_imp_df <- data.frame()

    # Fold-wise training
    for (fold_index in seq_along(folds)) {
      cat(
        "Fold: ", fold_index, "\n"
      )
      train_indices <- setdiff(seq_len(nrow(full_df)), folds[[fold_index]])
      valid_indices <- folds[[fold_index]]

      train_data <- xgb.DMatrix(data = as.matrix(X[train_indices, ]), label = y[train_indices])
      valid_data <- xgb.DMatrix(data = as.matrix(X[valid_indices, ]), label = y[valid_indices])

      xgb_model <- xgb.train(
        data = train_data,
        nrounds = selected_trees,
        objective = "reg:squarederror",
        eval_metric = "rmse",
        max_depth = selected_max_depth,
        min_child_weight = selected_min_child,
        early_stopping_rounds = early_stop,
        eta = selected_eta,
        gamma = selected_gamma,
        watchlist = list(eval = valid_data),
        print_every_n = print_every,
      )

      # Store OOF predictions
      oof_predictions[valid_indices] <- predict(xgb_model, valid_data)

      # Create the feature importance matrix
      importance_matrix <- xgb.importance(feature_names = colnames(X), model = xgb_model)

      # Store the importance matrix in the dataframe
      feature_imp_df <- rbind(feature_imp_df, as.data.frame(importance_matrix))
    }

    # Store the predictions in the corresponding column
    base_oof_predictions[[paste0("pred_", selected_feature)]] <- oof_predictions

    # Modify the feature importance matrix
    feature_imp_df <- feature_imp_df %>%
      group_by(Feature) %>%
      summarise_all(mean) %>%
      # create the combined normalised importance
      mutate(
        Combined = rowSums(across(.cols = -Feature))
      ) %>%
      mutate(
        Normalised = Combined / sum(Combined),
        Target = feature
      ) %>%
      arrange(desc(Normalised))

    # Add the feature importance matrix to the full dataframe
    full_feature_imp_df <- rbind(full_feature_imp_df, feature_imp_df)

    # Save the feature importance df
    write.csv(
      feature_imp_df,
      paste0(
        "Data/Gen_model_output/Results/Feature_importance/",
        feature,
        "_feature_importance.csv"
      )
    )
  } else {
    cat("Feature not found")
  }
}
# Save the predictions
write.csv(
  base_oof_predictions,
  "Data/Gen_model_output/Predictions/Base_predictions/Full_base_predictions.csv"
)
write.csv(
  base_oof_predictions,
  "Data/Gen_model_input/Base_predictions/Full_base_predictions.csv"
)

# Save the full feature importance dataframe
write.csv(
  full_feature_imp_df,
  "Data/Gen_model_output/Results/Feature_importance/Full_feature_importance.csv"
)

cat("Training the base models complete")
```


```


META MODEL INITIALIZATION
```{r}
# Upload the base predictions
base_oof_predictions <- read.csv(
  paste0(
    input_path,
    "Base_predictions/Full_base_predictions.csv"
  ),
  row.names = 1
)

# Create the training folds
meta_folds <- createFolds(base_oof_predictions[["act_1p"]], k = 5, list = TRUE, returnTrain = FALSE)

# Create the empty dataframe that will store the out-of-fold predictions for each model of the meta learners
meta_oof_predictions <- data.frame(
  matrix(
    ncol = length(response_features),
    nrow = length(combine_all_folds(meta_folds))
  )
)
colnames(meta_oof_predictions) <- paste0("pred_", response_features)

cat("\n Predictions Dataframe:  \n")
print(head(meta_oof_predictions[1:5]))

meta_oof_predictions <- cbind(
  meta_oof_predictions,
  labels
) %>%
  arrange(act_index) %>%
  column_to_rownames("act_index")
```

META TRAINING
```{r}
# Create the predictor data for the meta learners
meta_input_data <- base_oof_predictions %>%
  select(starts_with("pred_"))

# Create the full feature importance dataframe
full_feature_imp_df <- data.frame()

for (feature in response_features) {
  cat(
    "Feature: ", feature, "\n\n"
  )

  # Get the parameters from stored Parameters file
  parameters <- meta_parameters

  # select the parameters and weights corresponding to the index
  selected_parameters <- parameters[parameters$Feature == feature, ]

  selected_feature <- selected_parameters$Feature
  selected_trees <- as.numeric(selected_parameters$Trees) + 500
  selected_eta <- selected_parameters$Eta
  selected_gamma <- selected_parameters$Gamma
  selected_max_depth <- selected_parameters$Max_depth
  selected_min_child <- selected_parameters$Child_weight

  cat(
    "\n Selected Parameters: \n",
    "Feature: ", selected_feature, "\t",
    "Trees: ", selected_trees, "\t",
    "Eta: ", selected_eta, "\n",
    "Gamma: ", selected_gamma, "\t",
    "Max Depth: ", selected_max_depth, "\t",
    "Min Child: ", selected_min_child, "\n"
  )

  y <- as.integer(base_oof_predictions[[paste0("act_", feature)]])
  X <- meta_input_data

  # Create the out-of-fold predictions column
  oof_predictions <- numeric(nrow(X))

  # Create df to store the importance matrix
  feature_imp_df <- data.frame()
  if (feature %in% cat_features) {

    # Set the weights
    selected_weights <- base_cat_parameters[base_cat_parameters$Feature == feature, c("Weight_loss", "Weight_normal", "Weight_gain")]

    # Fold-wise training
    for (fold_index in seq_along(folds)) {
      cat(
        "Fold: ", fold_index, "\n"
      )
      train_indices <- setdiff(seq_len(nrow(full_df)), folds[[fold_index]])
      valid_indices <- folds[[fold_index]]

      train_data <- xgb.DMatrix(data = as.matrix(X[train_indices, ]), label = y[train_indices])
      valid_data <- xgb.DMatrix(data = as.matrix(X[valid_indices, ]), label = y[valid_indices])

      train_y_factor <- factor(y[train_indices], levels = c(0, 1, 2))
      weights <- as.numeric(feature_digit_function(train_y_factor))
      setinfo(train_data, "weight", weights)

      xgb_model <- xgb.train(
        data = train_data,
        nrounds = selected_trees,
        objective = "multi:softmax",
        eval_metric = "mlogloss",
        max_depth = selected_max_depth,
        min_child_weight = selected_min_child,
        early_stopping_rounds = early_stop,
        eta = selected_eta,
        gamma = selected_gamma,
        watchlist = list(eval = valid_data),
        num_class = 3,
        print_every_n = print_every,
      )

      # Store OOF predictions
      oof_predictions[valid_indices] <- predict(xgb_model, valid_data)

      # Create the feature importance matrix
      importance_matrix <- xgb.importance(feature_names = colnames(X), model = xgb_model)

      # Store the importance matrix in the dataframe
      feature_imp_df <- rbind(feature_imp_df, as.data.frame(importance_matrix))
    }

    # Store the predictions in the corresponding column
    meta_oof_predictions[[paste0("pred_", selected_feature)]] <- oof_predictions

  } else if (feature %in% reg_features) {

    xgb_meta_model <- xgb.cv(
      data = xgb_data,
      nrounds = selected_trees,
      objective = "reg:squarederror",
      eval_metric = "rmse",
      early_stopping_rounds = early_stop,
      folds = meta_folds,
      max_depth = selected_max_depth,
      min_child_weight = selected_min_child,
      eta = selected_eta,
      gamma = selected_gamma,
      print_every_n = print_every,
      prediction = TRUE
    )

    # Store the predictions in the corresponding column
    meta_oof_predictions[[paste0("pred_", selected_feature)]] <- xgb_meta_model$pred
  } else {
    cat("Feature not found")
  }
}

cat("Training of the meta models complete")

# Save the out-of-fold predictions
write.csv(
  meta_oof_predictions,
  "Data/Gen_model_output/Predictions/Meta_predictions/Full_meta_predictions.csv"
)
write.csv(
  meta_oof_predictions,
  "Data/Gen_model_input/Meta_predictions/Full_meta_predictions.csv"
)
```

Reconvert the data into the original scale
```{r}
# Upload the meta predictions
meta_oof_predictions <- read.csv(
  paste0(
    input_path,
    "Meta_predictions/Full_meta_predictions.csv"
  ),
  row.names = 1
)

# columns to not convert
regression_columns <- c(
  paste("pred_", reg_features, sep = ""),
  paste("act_", reg_features, sep = "")
)

# Reconvert the data into the original scale
final_base_oof_predictions <- base_oof_predictions %>%
  mutate(across(.cols = -SampleID, .fns = as.numeric)) %>%
  mutate(across(.cols = -c("SampleID", regression_columns), ~ replace(., . == 0, -1))) %>%
  mutate(across(.cols = -c("SampleID", regression_columns), ~ replace(., . == 1, 0))) %>%
  mutate(across(.cols = -c("SampleID", regression_columns), ~ replace(., . == 2, 1)))

final_meta_oof_predictions <- meta_oof_predictions %>%
  mutate_all(as.numeric) %>%
  mutate(across(.cols = -regression_columns, ~ replace(., . == 0, -1))) %>%
  mutate(across(.cols = -regression_columns, ~ replace(., . == 1, 0))) %>%
  mutate(across(.cols = -regression_columns, ~ replace(., . == 2, 1)))
```


Assess the performance of the models
```{r}
Class_metrics_df <- data.frame(
  Feature = character(),
  Class = character(),
  Type = character(),
  Metric = character(),
  Value = numeric()
)

Cat_general_metrics <- data.frame(
  Feature = character(),
  Type = character(),
  Accuracy = numeric(),
  Kappa = numeric(),
  AccuracyNull = numeric(),
  AccuracyPValue = numeric()
)

Reg_general_metrics <- data.frame(
  Feature = character(),
  Type = character(),
  RMSE = numeric(),
  MAE = numeric()
)

# Assess the performance of the models
for (feature in response_features) {
  predicted <- paste0("pred_", feature)
  labelled <- paste0("act_", feature)

  if (feature %in% cat_features) { # Categorical features
    # Use Caret package to get the performance stats
    cm_base <- calculate_confusion_matrix(final_base_oof_predictions, predicted, labelled)
    cm_meta <- calculate_confusion_matrix(final_meta_oof_predictions, predicted, labelled)

    # Update the general metrics dataframeß
    cat_base_metrics <- as.data.frame(cm_base$overall) %>%
      t() %>%
      as.data.frame() %>%
      mutate(Feature = feature, Type = "Base") %>%
      select(Feature, Type, everything())

    cat_meta_metrics <- as.data.frame(cm_meta$overall) %>%
      t() %>%
      as.data.frame() %>%
      mutate(Feature = feature, Type = "Meta") %>%
      select(Feature, Type, everything())

    Cat_general_metrics <- rbind(
      Cat_general_metrics,
      cat_base_metrics,
      cat_meta_metrics
    )

    # # Create the TPR confusion matrix and the heatmap
    # tpr_mtrx_base <- tpr_confusion_matrix(cm_base, feature, "Base")
    # tpr_mtrx_meta <- tpr_confusion_matrix(cm_meta, feature, "Meta")

    # Create the confusion matrix stats
    confusion_matrix_data <- rbind(
      create_confusion_matrix_data(cm_meta, "Meta"),
      create_confusion_matrix_data(cm_base, "Base")
    ) %>%
      mutate(Feature = feature) %>%
      select(Feature, everything())

    # Update the class metrics dataframe
    Class_metrics_df <- rbind(Class_metrics_df, confusion_matrix_data)

    # Create the plot for the stats above
    metrics_plot <- confusion_stat_plot(confusion_matrix_data)
  } else if (feature %in% reg_features) { # Regression models
    # evaluate the performance of the regression models with caret

    # Calculate the RMSE for the regression models
    rmse_base <- caret::RMSE(
      final_base_oof_predictions[[predicted]],
      final_base_oof_predictions[[labelled]]
    )
    rmse_meta <- caret::RMSE(
      final_meta_oof_predictions[[predicted]],
      final_meta_oof_predictions[[labelled]]
    )

    # Calulate the MAE for the regression models
    mae_base <- caret::MAE(
      final_base_oof_predictions[[predicted]],
      final_base_oof_predictions[[labelled]]
    )
    mae_meta <- caret::MAE(
      final_meta_oof_predictions[[predicted]],
      final_meta_oof_predictions[[labelled]]
    )

    # Calculate the R2 for the regression models
    r2_base <- caret::R2(
      final_base_oof_predictions[[predicted]],
      final_base_oof_predictions[[labelled]]
    ) %>% round(., 2)

    r2_meta <- caret::R2(
      final_meta_oof_predictions[[predicted]],
      final_meta_oof_predictions[[labelled]]
    ) %>% round(., 2)


    # Update the general metrics dataframe
    Reg_general_metrics <- rbind(
      Reg_general_metrics,
      data.frame(
        Feature = feature,
        Type = "Base",
        RMSE = rmse_base,
        MAE = mae_base,
        R_squared = r2_base
      ),
      data.frame(
        Feature = feature,
        Type = "Meta",
        RMSE = rmse_meta,
        MAE = mae_meta,
        R_squared = r2_meta
      )
    )

    # Create the actual vs predicted plot f
    # Function to create a predicted vs actual plot
    create_pred_vs_actual_plot <- function(data, feature, type, plot_title_prefix = "Predicted vs Actual for ") {
      ggplot(data, aes_string(
        x = paste0("pred_", feature), # Predicted on x-axis
        y = paste0("act_", feature) # Actual on y-axis
      )) +
        geom_point() +
        geom_smooth(method = "lm", se = FALSE, color = "blue") +
        labs(
          title = paste0(plot_title_prefix, str_replace_all(feature, "_", " ")),
          x = "Predicted",
          y = "Actual",
          caption = paste0("Linear Regression R² = ", get(paste0("r2_", type)))
        ) +
        theme_minimal() +
        theme(
          plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
          axis.title = element_text(size = 14),
          panel.border = element_rect(linetype = "solid", color = "black", fill = NA, size = 0.5),
          panel.grid.major = element_line(color = "gray20", size = 0.2),
          panel.grid.minor = element_line(color = "gray85", size = 0.1)
        )
    }

    plot_base_reg <- create_pred_vs_actual_plot(
      final_base_oof_predictions,
      feature,
      "base",
      "Base model residuals for "
    )

    plot_meta_reg <- create_pred_vs_actual_plot(
      final_meta_oof_predictions,
      feature,
      "meta",
      "Meta model residuals for "
    )

    print(plot_meta_reg)
  }
}

# Reset the indices of the dataframes to row number
Cat_general_metrics <- Cat_general_metrics %>%
  rownames_to_column("Index") %>%
  select(-Index) %>%
  distinct() %>%
  select(Feature, Type, Accuracy, Kappa, AccuracyNull, AccuracyPValue)

Reg_general_metrics <- Reg_general_metrics %>%
  rownames_to_column("Index") %>%
  select(-Index) %>%
  distinct()

Class_metrics_df <- Class_metrics_df %>%
  distinct()

# Save the dataframes
write.csv(
  Cat_general_metrics,
  "Data/Gen_model_output/Results/Gen_cat_metrics.csv"
)

write.csv(
  Reg_general_metrics,
  "Data/Gen_model_output/Results/Gen_reg_metrics.csv"
)

write.csv(
  Class_metrics_df,
  "Data/Gen_model_output/Results/Gen_cat_class_metrics.csv"
)
```



